---
title: "CCVA_Processing"
author: "KEC"
date: "2024-04-04"
output: html_document
editor_options: 
  chunk_output_type: console
---

## CCVA Data Processing 

This R markdown prepares data inputs for a Climate Change Vulnerability Assessment (CCVA) for water supplies at a selected National Park.

### Setup Workspace

First, install and/or load required packages and functions.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
source('setup.R')

```

### Download data

Various climate, hydrology, and geography data are required to generate a CCVA for the selected National Park. The following code chunks download and describe this data.

##### 1. Park name and boundary

Start by specifying which National Park to obtain data for by assigning the "park" variable with the four digit Unit List code. Codes for all parks can be found at: <https://www.nps.gov/aboutus/foia/upload/NPS-Unit-List.xlsx>.

Once the park is specified, download the park boundary from the NPS IRMA DataStore as an sf object.

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# Assign park variable with 4 digit Unit code 
park <- "BRCA"

# Get park boundary
park_boundary <- getParkBoundary(park = park)

# Get park name
park_name <- park_boundary$UNIT_NAME
```

##### 2. Watersheds and NHD flowlines

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# Get watersheds within park boundary
park_watershed <- getWatersheds(aoi = park_boundary, 
                                clipped = FALSE,
                                save = FALSE)

# Get flowlines within park boundary
park_flowlines <- park_watershed %>%
            dplyr:: summarize() %>%
            mapNHDPlusHR() %>%
            dplyr:: summarize()

```

##### 3. Points of diversion and water supply for park

Park water supplies may be sourced from within or beyond the park boundary. This chunk pulls in state-reported water supply locations that occur within a buffer distance from both the park boundary. It also pulls in the watersheds that intersect with those points. Because water supply locations are reported by state, state-specific functions are utilized.

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# ****KEC: This should be nested into a getPODall function with aoi and dist
# args which then applies the state-specific function.

# Get state specific points of diversion (POD) (i.e., water supply points)
buffer_dist <- 0.1 # in decimal degrees lat/long

# State specific functions - need to make for rest of states
if (park_boundary$STATE == "AL") {}

if (park_boundary$STATE == "CA") {
  POD_state <- getPODCalifornia(aoi = park_watershed, 
                                dist = buffer_dist)
} else if (park_boundary$STATE == "NV") {
  POD_state <- getPODNevada(aoi = park_watershed, 
                            dist = buffer_dist)
} else if (park_boundary$STATE == "UT") {
  POD_state <- getPODUtah(aoi = park_watershed, 
                          dist = buffer_dist)
} 

```

Now, if POD are available, identify potential water supply from those state-wide PODs.
        - For some parks, the water supply ID is known.  Select the known
          supply by ID for those parks.
        - Where it is unknown, assume the water supply is any POD owned by
          NPS and located within the buffer distance.

****KEC: This assumes POD_state has "OWNER" column and that NPS is identified 
by string "NATIONAL PARK". Should probably update match strings in future as 
other POD databases are brought in. 


```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

if (!is_empty(POD_state)) {
# Utah col descriptions for POD_supply 
#.  -> https://www.arcgis.com/sharing/rest/content/items/5d530e62e6ca42528dd13e0a453a3b73/info/metadata/metadata.xml?format=default&output=html
# Some states have a known supply. If so, assign.
if (park == "BRCA") {
    POD_supply <- POD_state %>%
    dplyr::filter(WRNUM %in% c("61-893", "2061001M00")) %>%
    dplyr::distinct(LOCATION, .keep_all = TRUE)
} else {
    POD_supply <- POD_state %>%
    dplyr::filter(OWNER %like% "NATIONAL PARK",
                  #USES %in% c("D","M","MO"),
                  str_detect(USES,"D|M|O")) %>% # municipal, domestic, or other
    dplyr::distinct(LOCATION, .keep_all = TRUE) %>%
      dplyr::distinct(WRNUM, .keep_all = TRUE)
}

# Get watershed intersecting each watersupply point
watersupply_watershed <- vector("list", nrow(POD_supply))  
  
for(i in 1:nrow(POD_supply)){
  watersupply_watershed[[i]] <- POD_supply[i,] %>% 
  getXYWatersheds(sf = ., coordinates = NULL)
}

watersupply_watershed <- watersupply_watershed %>%
  dplyr::bind_rows() %>% 
  dplyr::distinct(featureid, .keep_all = TRUE) 

# Get flowlines associated with watersupply watershed
watersupply_flowlines <- watersupply_watershed %>%
              dplyr::summarize() %>%
              mapNHDPlusHR()
}


watersupply_watershed_area <- st_area(dplyr::summarize(watersupply_watershed))


```

##### 4. Centroids

Climate futures have been previously compiled for park and Koppen centroids. Check which of these best represents conditions at the (potential) source(s) for the park's water supply.

Source for Koppen-Geiger climate classification maps:

Beck, H. E., Zimmermann, N. E., McVicar, T. R., Vergopolan, N., Berg, A., & Wood, E. F. (2018). Present and future KÃ¶ppen-Geiger climate classification maps at 1-km resolution. Scientific data, 5(1), 1-12.

<https://figshare.com/articles/dataset/Present_and_future_K_ppen-Geiger_climate_classification_maps_at_1-km_resolution/6396959/2>

#### First get Koppen climate data for park

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# Get koppen climate grid for park with buffer
koppen_park <- get_koppen(aoi = park_boundary, 
                             buffer_dist = 0.1)


# Get koppen climate intersecting watershed
# create a merged watersupply watershed for subsequent functions
ws_union <- sf::st_union(watersupply_watershed) %>%
            sf::st_as_sf()

koppen_ws <- get_koppen(aoi = ws_union, 
                           buffer_dist = 0) %>%
            sf::st_transform(., crs = sf::st_crs(ws_union)) %>%
            dplyr::filter(st_intersects(., ws_union) %>% 
            as.logical())
            

# Create a table of Koppen and park centroids with area span for each koppen
# climate that overlaps with watersupply watershed (from above) and distance
# between centroid location and watersupply watershed. 

#****KEC:  Note, nothing is done with this as of now, but we can incorporate 
#* later

centroid_sel <- 
  # get table of koppen centroids from web
  GET('https://parkfutures.s3.us-west-2.amazonaws.com/maca-tprh-data/0Climate_Zones_by_Unit_cleaned.csv') %>% 
            as.character() %>% 
            data.table::fread(.,header = TRUE, skip = 1) %>%
            dplyr::filter(UNIT_CODE == park) %>%
            sf::st_as_sf(coords = c("Lon","Lat"), 
                        crs = sf::st_crs(watersupply_watershed)) %>%
            # Calc. distance between centroid and watersupply watershed
            dplyr::mutate(dist = (sf::st_distance(geometry,ws_union))) %>%
            # Add park centroid point
            bind_rows(sf::st_centroid(park_boundary) %>% 
                      st_as_sf() %>%
                      dplyr::mutate(dist = (sf::st_distance(Shape, ws_union)))) %>%
            sf::st_set_geometry(., NULL) %>%
            # Clean some metadata / cols
            dplyr::select(c(ClimateZone,dist)) %>%
            dplyr::mutate(CZ_str = sprintf("_%02d", ClimateZone),
                          CZ_str = str_replace(CZ_str, "_NA", ""),
                          centroid = paste0(park,CZ_str)) %>%
          dplyr::left_join(koppen_ws %>% dplyr::count(K_vals), 
                           by = c("ClimateZone" ="K_vals")) %>%
          dplyr::select(-CZ_str)

# Pull centroid with minimum distance to watersupply watershed
min_dist_cent <- centroid_sel[which.max(centroid_sel$n),]$centroid
# Pull centroid corresponding to maximum overlap with watersupply watershed
max_overlap_cent <- centroid_sel[which.max(centroid_sel$n),]$centroid



```

##### 5. Get Climate data for park centroid

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# Import table of selected futures for site. Selections were made using the "select_GCMs" 
# function. 
select_cfs <- data.table::fread('data/parkwide_GCMs.csv') %>% 
              mutate_at("centroid", str_replace, "_future", "") %>%
              dplyr::filter(park %in% {{park}},
                            CF %in% c("Warm Wet", "Hot Dry")) %>%
              # Uncomment either:
              # a. if using min distance to supply watershed 
              dplyr::filter(centroid == min_dist_cent)
              # or b.if using max overlap with supply watershed
              #dplyr::filter(centroid == max_overlap_cent)

# replacement for now until selection is fixed
select_cfs[select_cfs$GCM=="MIROC-ESM.rcp85",]$GCM <- "MIROC-ESM-CHEM.rcp85"

# ****KEC: update function to check if files exist before downloading.
get_centroid_climate_data(park = park, save = TRUE)

# Directory to which files were downloaded.
climate_dir <- paste0("data/park/",park,"/centroid/climate")

# Import centroid climate data
centroid_climate <- base::list.files(climate_dir,full.names = TRUE) %>%
            purrr::map(~ read_csv(.x) %>% 
            dplyr::mutate(Unit_ClimateZone = str_remove_all(basename(.x),
                              "_(?<=_)(future|historical)\\.csv"))) %>%
            dplyr::bind_rows() %>%
            dplyr::left_join(select_cfs, by = "GCM") %>%
            dplyr::mutate(CF = ifelse(GCM %in% "gridmet.historical","Historical",CF)) %>%
            janitor::clean_names() %>%
            dplyr::select(-c(park, delta_tavg,delta_pr)) %>%
            dplyr::filter(unit_climate_zone == select_cfs$centroid[1])


```

##### 6. WBM Data

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# Download centroid data -- will need to update for each park
get_centroid_wbm_data(park = park)
    
## Note, currently getting an error with save = FALSE in function call

wbm_dir <- paste0("data/park/",park,"/centroid/wbm/")

centroid_wbm <- list.files(wbm_dir,full.names = TRUE) %>% 
            purrr::map(~ read_csv(.)) %>% 
            bind_rows() %>%
            left_join(select_cfs, by = "GCM") %>%
            dplyr::mutate(CF = ifelse(GCM %in% "gridmet.historical","Historical",CF)) %>%
            janitor::clean_names() %>%
            dplyr::select(-c(park,lat,lon,delta_tavg,delta_pr, period)) %>%
            dplyr::filter(unit_climate_zone == select_cfs$centroid[1])

# 30 year WBM stats
park_boundary <- getParkBoundary("BRCA")
aoi <- park_boundary %>% st_buffer(.2)
variable <- c("runoff")
cf <- select_cfs$GCM
scen <- select_cfs$CF

wbm_30y <- get30yearWBMGridMET(aoi = aoi,
                                     variable = variable,
                                     cf = cf,
                                     save = TRUE,
                                     path = "data/all",
                                     filename_prefix = "BRCA")

warm_wet_diff_30y <- lapp(c(wbm_30y[[5]],wbm_30y[[1]]), 
                 fun = function(x,y) { (x - y) / x })

hot_dry_diff_30y <-lapp(c(wbm_30y[[5]],wbm_30y[[3]]), 
                 fun = function(x,y) { (x - y) / x })

#library(leaflet)
# leaflet() %>% addTiles() %>% 
#  addRasterImage(x = wbm_30y[[1]], colors = brewer.pal(11,"RdBu"), opacity = 0.8) %>%
#  addLegend(pal = brewer.pal(11,"BrBG"), values = values(wbm_30y[[1]]))

```

##### 7. Water use data

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# Get state specific water use data --> in monthly format

if (park_boundary$STATE == "UT") {

  water_supply_id <- getWaterSuppliersUtah(aoi = park_boundary) %>%
    filter(grepl("National Park", WRNAME, ignore.case=TRUE)) %>%
    .$WRID

  # Park specific selections based on known ID
  
  if (park == "BRCA") {
    
    water_use_1 <- getWaterUseUtah(WRID = water_supply_id)[[1]] %>%
                  slice(1:39) %>%
                  pivot_longer(-c("Year", "Method of Measurement"), 
                               names_to = "month", 
                               values_to = "use_acre_feet") %>%
                  dplyr::mutate(ym = ym(paste0(Year, "-", month))) %>%
                  dplyr::filter(month != "Annual inAcre Feet") %>%
                  dplyr::select(ym, use_acre_feet) %>%
                  dplyr::mutate(well = "Well 1")
  
  # Well 2
  water_use_2 <- getWaterUseUtah(WRID = water_supply_id)[[1]] %>%
                  slice(51:nrow(.)) %>%
                  dplyr::filter(!is.na(as.numeric(Year))) %>%
                  pivot_longer(-c("Year", "Method of Measurement"), 
                               names_to = "month", 
                               values_to = "use_acre_feet") %>%
                  dplyr::mutate(ym = ym(paste0(Year, "-", month))) %>%
                  dplyr::filter(month != "Annual inAcre Feet") %>%
                  dplyr::select(ym, use_acre_feet) %>%
                  dplyr::mutate(well = "Well 2")
  
  # join water use data
  water_use <- water_use_1 %>%
              dplyr::bind_rows(water_use_2) %>%
              dplyr::group_by(ym) %>%
              dplyr::summarize(use_acre_feet = sum(as.numeric(use_acre_feet), 
                                                   na.rm = TRUE))
  
    rm(list = c("water_use_1", "water_use_2"))
  
  } else {
    
  # For UTAH parks without specific info on # of wells, etc, sum all
  # use for each month.
  water_use <- getWaterUseUtah(WRID = water_supply_id)[[1]] %>%
                dplyr::filter(!is.na(suppressWarnings(as.numeric(Year)))) %>%
                tidyr::pivot_longer(-c("Year","Method of Measurement"), 
                             names_to = "month", 
                             values_to = "use_acre_feet") %>%
                dplyr::filter(month != "Annual inAcre Feet") %>%
                dplyr::mutate(ym = ym(paste0(Year, "-", month))) %>%
                dplyr::group_by(ym) %>%
                dplyr::summarize(use_acre_feet = sum(as.numeric(use_acre_feet), 
                                                     na.rm = TRUE)) 
  }

}



```

##### 8. USGS gages within the park or POD watershed

For many parks, the nearest USGS stream gage is far away. Therefore, we are pulling all NWIS gages within 100 km of the park boundary. Of those, we only select stream gages that are considered "reference" gages in the [GAGES-II database (Falcone, 2011)](https://pubs.usgs.gov/publication/70046617). Then, we delineate each of those gages' watersheds using the `get_nldi_basin()` function from the {nhdplusTools} package:

```{r, eval = TRUE, message = FALSE, warning = FALSE}

# Get all NWIS sites
nwis <- listNWIS(aoi = watersupply_watershed %>% dplyr::summarize(), dist = .3) #%>%


  #dplyr::filter(data_type_cd == "dv",
  #       code == "00060")

# Get NWIS Stream Gages
ref_gages <- get_gagesII(id = nwis$site_no) %>%
             dplyr::filter(class == "Ref")

nwis_stream <- nwis %>%
              dplyr::filter(site_no %in% ref_gages$staid,
                            data_type_cd == "dv") %>%
              dplyr::left_join(st_drop_geometry(ref_gages), 
                               by = c("site_no" ="staid")) 

# Download data from reference stream sites
nwis_stream_discharge <- 
  dataRetrieval::readNWISdv(siteNumbers = nwis_stream$site_no,
                            parameterCd = c('00060','00065')) %>%
    dplyr::mutate(y = year(Date), m = month(Date)) %>%
    dplyr::filter(y >= 1980) %>%
    dplyr::group_by(y,m, site_no) %>%
    dplyr::summarize(mean_discharge = mean(X_00060_00003, na.rm. = TRUE),
                     .groups = "keep") %>%
    dplyr::ungroup() %>%
    dplyr::mutate(ym = lubridate::make_date(year = y, month = m, day = 1)) %>% 
    dplyr::select(ym, site_no, mean_discharge) %>%
    tidyr::pivot_wider(names_from = site_no, 
                       names_prefix = "gage_", 
                       values_from = mean_discharge) #%>%

# Download data from reference stream sites
#getNWIS(inventory = nwis_stream, park = "misc", path = "data/")


# Define functions to get those watersheds for ref. gages using get_nldi_basin 
# in from {nhdplusTools}.

# ================ Function to identify NLDI watersheds ========================


# Now, use functions to get watersheds associated with stream gages
nldi_watershed <- nwis_stream$site_no %>%
                purrr::map_dfr(~nldi_finder(site_no = .)) %>%
                dplyr::mutate(data = map(site_no, ~nldi_meta(site_no = .))) %>%
                unnest(cols = c(data)) %>%
                dplyr::left_join(st_drop_geometry(nwis), by = "site_no")

nldi_flowlines <- dplyr::summarize(nldi_watershed) %>%
                  mapNHDPlusHR() %>% 
                  dplyr::summarize()


# Now Get Gw sites

nwis_groundwater <- nwis %>%
  dplyr::filter(begin_date != end_date,
         n_obs > 50,
         # groundwater sites only:
         site_type_cd == "GW",
         data_type_cd == "gw",
         code == 72019) %>%
  dplyr::mutate(dist = st_distance(geometry,park_boundary) %>%
                  as.numeric()) %>%
         dplyr::filter(dist <= 1600*3) %>%
  add_gw_meta()


# pull those sites groundwater level data
  nwis_groundwater_levels <- dataRetrieval::readNWISgwl(nwis_groundwater$site_no) %>%
    dplyr::filter(parameter_cd == 72019,
                  year(lev_dt) >= 1980) %>% # 72019 =Depths, 62611=elevation
    dplyr::mutate(ym = lubridate::ym(substr(lev_dt, 1, 7))) %>% 
    dplyr::group_by(ym, site_no) %>%
    dplyr::summarize(mean_lev_va = mean(lev_va, na.rm. = TRUE), 
                     .groups = "keep") %>%
    dplyr::select(ym, site_no, mean_lev_va) %>%
    tidyr::pivot_wider(names_from = site_no, names_prefix = "well_", values_from = mean_lev_va) #%>%


```

##### 9. Park Visitation

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}
# NPS monthly visitor information
visitors <- 
  getUnitVisitation(units = park, startYear = 1980, endYear = 2023) %>%
  dplyr::mutate(ym = ym(paste0(Year, "-", Month))) %>%
  dplyr::mutate(TotalVisitors = RecreationVisitors + NonRecreationVisitors) %>%
  dplyr::select(ym, RecreationVisitors, TotalVisitors) %>%
  mutate(ifelse(TotalVisitors == 0,NA,TotalVisitors),
         ifelse(RecreationVisitors ==0, NA, RecreationVisitors))


```



### Begin data analysis

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# First Aggregate datasets


# Set date range for historic and future aggregation periods
hist_years <- c(1980,2010)      # 30 year
future_years <- c(2040,2070)   # 30 year

# For temporal aggregations, some variables will be summarized using the mean 
# while others will use the sum. Define which cols for subsequent calculations
mean_cols <- c("tavg_f", "tmax_f","tmin_f", "r_hmax_percent", "r_hmin_percent",
               "deficit_in", "soil_water_in", "runoff_in", "accumswe_in")
sum_cols <- c("precip_in", "rain_in", "aet_in", "pet_in", "days_gt_92F", 
              "days_lt_32F", "days_gt_95pcp", "days_gt_95roff", 
              "days_gt_77F", "days_lt_05roff", "days_w_pcp","days_w_swe")


#

################################ Daily Stats ###################################

# First, calculate some generic stats on daily data for historic and future
# periods of interest

# Join centroid data
centroid_all <- left_join(centroid_climate %>%
                            dplyr::filter(!is.na(cf)), # removes non-selected
                          centroid_wbm %>%
                            dplyr::filter(!is.na(cf)), 
                by = c("date","gcm","cf", "centroid","unit_climate_zone")) 

stats <- centroid_all %>%
  dplyr::mutate(stat_group = 
               dplyr::case_when(year(date) > hist_years[1] & 
                                year(date) < hist_years[2] ~ "Historical",
                                year(date) > future_years[1] & 
                                year(date) < future_years[2] ~ "Future")) %>%
  tidyr::drop_na(any_of("stat_group")) %>%
  dplyr::select(-c(date,gcm,unit_climate_zone,centroid)) %>%
  dplyr::group_by(cf,stat_group) %>%
  dplyr::summarize_all(.funs = 
                        list(Q95 = ~ quantile(., probs = 0.95, na.rm = TRUE),
                             Q05 = ~ quantile(., probs = 0.05, na.rm = TRUE),
                            mean = ~ mean(., na.rm = TRUE),
                          median = ~ median(., na.rm = TRUE),
                              sd = ~ sd(., na.rm = TRUE)),
                       .groups = "keep")


# Now, add binary indicator to get day counts (e.g., 1 for days over X degrees,
# 0 for days under X degrees)
centroid_all <- centroid_all %>%
  group_by(cf) %>%
      # Get day counts for conditional statistics
      dplyr::mutate(days_gt_92F = ifelse(tmax_f > 92, 1,0),
                    days_gt_77F = ifelse(tmax_f > 77, 1,0),
                    days_lt_32F = ifelse(tmin_f < 32, 1,0),
                    days_w_pcp = ifelse(precip_in >0,1,0),
                    days_w_swe = ifelse(accumswe_in >0,1,0),
                  days_gt_95pcp = ifelse(precip_in >= stats[stats$stat_group == 
                                              "Historical",]$precip_in_Q95,1,0),
                 days_gt_95roff = ifelse(runoff_in >= stats[stats$stat_group == 
                                              "Historical",]$runoff_in_Q95,1,0),
                 days_lt_05roff = ifelse(runoff_in <= stats[stats$stat_group == 
                                              "Historical",]$runoff_in_Q05,1,0))


############################## Seasonal Stats ##################################

# Create Seasonal Dataframe
centroid_seasonal <- centroid_all %>%
  dplyr::mutate(season = case_when(month(date) %in% c(12,1,2) ~ "Winter",
                            month(date) %in% c(3,4,5) ~ "Spring",
                            month(date) %in% c(6,7,8) ~ "Summer",
                            month(date) %in% c(9,10,11) ~ "Fall")) %>%
  dplyr::mutate(y = year(date)) %>%
  dplyr::select(-c(date,gcm)) %>%
  dplyr::group_by(y,season,cf)%>%
  dplyr::summarize(
              across(all_of(sum_cols),sum),  # Sum of columns in sum_cols list
              across(all_of(mean_cols),mean),
              .groups = "keep")


hist_95th_pctl_spring_roff <- centroid_seasonal %>% 
                      filter(season == "Spring", 
                             y > hist_years[1] & y < hist_years[2]) %>%
                      pull(runoff_in) %>% 
                      quantile(.95)

seasonal_stats <- centroid_seasonal %>%
  dplyr::mutate(stat_group = 
                  ifelse(y > hist_years[1] & y < hist_years[2], "Historical",
                  ifelse(y > future_years[1] & y < future_years[2], 
                                    "Future",NA))) %>%
  dplyr::ungroup() %>%
  tidyr::drop_na(any_of("stat_group")) %>%
  dplyr::group_by(cf,stat_group,season) %>%
  dplyr::summarize_all(.funs = 
                        list(mean = ~ mean(., na.rm = TRUE),
                          median = ~ median(., na.rm = TRUE),
                              sd = ~ sd(., na.rm = TRUE)),
                       .groups = "keep")
  
############################## Monthly Stats ###################################

# Create Monthly Dataframe
centroid_monthly <- centroid_all  %>%
  # Group and summarize by month and year
            dplyr::mutate(y = year(date), m = month(date)) %>%
            dplyr::select(-c(date)) %>%
            dplyr::group_by(y,m,gcm,unit_climate_zone,cf) %>%
            dplyr::summarize(
              across(all_of(sum_cols),sum),  
              across(all_of(mean_cols),mean),
              .groups = "keep") %>%
            dplyr::mutate(ym = make_date(y,m), .before = gcm) %>%
            dplyr::ungroup() %>%
            dplyr::select(-c(y,m)) %>%
  # Add other monthly datasets to monthly
            dplyr::left_join(nwis_groundwater_levels, by = c("ym")) %>%
            dplyr::left_join(nwis_stream_discharge, by = c("ym")) %>%
            dplyr::left_join(visitors, by = c("ym")) %>%
            dplyr::left_join(water_use,by = c("ym")) %>%
  # calculate some new values
  mutate(demand_pp_af = use_acre_feet/TotalVisitors,
         demand_pp_gal = 325851 * demand_pp_af)

  
############################### Annual Stats ###################################

new_cols_sum <- c("use_acre_feet","TotalVisitors","RecreationVisitors")
new_cols_mean <- names(nwis_groundwater_levels)[2:length(names(nwis_groundwater_levels))]
# Create Annual Dataframe
centroid_annual <- centroid_monthly  %>%
            dplyr::mutate(y = year(ym)) %>%
            dplyr::select(-c(ym)) %>%
            dplyr::group_by(y,gcm,unit_climate_zone,cf) %>%
            dplyr::summarize(
              across(all_of(sum_cols),sum),  # Sum of columns in sum_cols list
              across(all_of(mean_cols),mean),
              across(all_of(new_cols_sum),sum),
              across(all_of(new_cols_mean),mean),
              .groups = "keep") %>%
          # recalculate demand with annual data
          mutate(demand_pp_af = use_acre_feet/TotalVisitors,
          demand_pp_gal = 325851 * demand_pp_af)


# Calculate future and historic means for each value.
annual_stats <- centroid_annual %>%
  dplyr::mutate(stat_group = 
                  ifelse(y > hist_years[1] & y < hist_years[2], "Historical",
                  ifelse(y > future_years[1] & y < future_years[2], 
                                    "Future",NA))) %>%
  dplyr::ungroup() %>%
  tidyr::drop_na(any_of("stat_group")) %>%
  dplyr::select(-c(gcm,unit_climate_zone)) %>%
  dplyr::group_by(cf,stat_group) %>%
  dplyr::summarize_all(.funs = 
                        list(mean = ~ mean(., na.rm = TRUE),
                          median = ~ median(., na.rm = TRUE),
                              sd = ~ sd(., na.rm = TRUE)),
                       .groups = "keep")

annual_percent <- (100*(annual_stats[2:5,3:ncol(annual_stats)] -           
                       annual_stats[rep(1,4),3:ncol(annual_stats)]) / 
                       annual_stats[rep(1,4),3:ncol(annual_stats)]) %>%
                      cbind(annual_stats[2:5,1:2],.)
  


############################## Runoff Stats ####################################

# KEC - there is a bimodal distribution for the day-of-year for the maximum
# precipitation AND correspondingly runoff. 

# Runoff magnitude
runoff_magnitude <- centroid_annual %>%
                  group_by(cf) %>% # convert to acre feet per year
                  dplyr::summarize(slope = 0.0254 * 
                                     as.numeric(st_area(park_boundary)) * 
                                     0.000810714 *
                                     coef(lm(runoff_in ~ y))[2], .groups = "keep") %>%
  mutate(dir = case_when(slope < 0 ~"decreased",
                             slope > 0 ~"increased",
                             slope == 0 ~ "remained unchanged") )


# Runoff timing 

# Group by year and select daily maximum discharge with corresponding date
max_annual_runoff <- centroid_all %>%
  mutate(Date = date,
         year = year(date)) %>%
  dplyr::select(c(Date,cf,year,runoff_in)) %>%
  addWaterYear() %>%
  dplyr::group_by(cf,waterYear) %>% 
  dplyr::slice_max(order_by = runoff_in, n=1, with_ties = FALSE) %>%
  mutate(doy = yday(Date),
         dowy = as.numeric(Date - as.Date(paste0(waterYear-1,"-10-01"))),
         season = case_when(month(Date) %in% c(12,1,2) ~ "Winter",
                            month(Date) %in% c(3,4,5) ~ "Spring",
                            month(Date) %in% c(6,7,8) ~ "Summer",
                            month(Date) %in% c(9,10,11) ~ "Fall"))



# calculate slopes, or rate of annual change. Negative indicates earlier runoff
spring_runoff_yearly_change <- max_annual_runoff %>%
  filter(season == "Spring" | season == "Winter") %>%
  group_by(cf) %>%
  dplyr::summarise(slope = coef(lm(doy ~ year))[2], .groups = "keep") %>%
      mutate(dir = case_when(slope < 0 ~"earlier",
                             slope > 0 ~"later",
                             slope == 0 ~ "unchanged"),
             slope_round = abs(round(slope,1)))

fall_runoff_yearly_change <- max_annual_runoff %>%
  filter(season == "Fall" | season == "Summer") %>%
  group_by(cf) %>%
  dplyr::summarise(slope = coef(lm(doy ~ year))[2], .groups = "keep")

max_annual_precip <- centroid_all %>%
  mutate(Date = date,
         year = year(date)) %>%
  dplyr::select(c(Date,cf,year,precip_in)) %>%
  addWaterYear() %>%
  dplyr::group_by(cf,waterYear) %>% 
  dplyr::slice_max(order_by = precip_in, n=1, with_ties = FALSE) %>%
  mutate(doy = yday(Date),
         dowy = as.numeric(Date - as.Date(paste0(waterYear-1,"-10-01"))),
         season = case_when(month(Date) %in% c(12,1,2) ~ "Winter",
                            month(Date) %in% c(3,4,5) ~ "Spring",
                            month(Date) %in% c(6,7,8) ~ "Summer",
                            month(Date) %in% c(9,10,11) ~ "Fall"))

# calculate slopes, or rate of annual change. Negative indicates earlier precip
spring_precip_yearly_change <- max_annual_precip %>%
  filter(season == "Spring" | season == "Winter") %>%
  group_by(cf) %>%
  dplyr::summarise(slope = coef(lm(doy ~ year))[2], .groups = "keep")

fall_precip_yearly_change <- max_annual_precip %>%
  filter(season == "Fall" | season == "Summer") %>%
  group_by(cf) %>%
  dplyr::summarise(slope = coef(lm(doy ~ year))[2], .groups = "keep")






############################ Visitation Stats ##############################

# 1. Describe changes in visitation using preceding 10 year means

# Get mean # annual visitors for years 2003-2013
visitor_2013_mean <- centroid_annual %>%
                      filter(y > 2003 & y <= 2013) %>%
                      pull(TotalVisitors) %>%
                      mean()

# Get mean # annual visitors for years 2013-2023
visitor_2023_mean <- centroid_annual %>%
                      filter(y > 2013 & y <= 2023) %>%
                      pull(TotalVisitors) %>%
                      mean()

# Compare with percent increase between two periods
visitor_2013_2023_change <- (100 * (visitor_2023_mean - visitor_2013_mean) / 
  visitor_2013_mean) %>%
  round(., digits = 0)


# 2. Develop statistical models to project future visitation

# A. Linear annual model projecting historic trends into future
#visitor_lm <- lm(TotalVisitors ~ y, data = centroid_annual %>%
#                                    filter(y < 2023))
# Add projected visitation to centroid_annual and centroid monthly datasets
#centroid_annual <- centroid_annual %>%
#  cbind(., predict(visitor_lm, centroid_annual, interval = "confidence") %>%
#          `colnames<-`(c( "TotalVisitors_lm_fit", 
#                          "TotalVisitors_lm_lwr",
#                          "TotalVisitors_lm_upr"))) 
# B. Monthly temperature based model
# Many factors drive global tourism, including financial constraints, 
# availability of leisure time, and weather and climate. Temperature has been
# identified as a strong predictor of visitation trends at national parks
# (Fisichelli et al., 2015). Here, we develop a multiple linear regression
# statistical model that uses mean monthly temperature, the number of days
# per month with temperatures greater than 92F, and the year to predict
# Total park visitors for that month.

# Fisichelli NA, Schuurman GW, Monahan WB, Ziesler PS (2015) Protected Area Tourism in a Changing Climate: Will Visitation at US National Parks Warm Up or Overheat? PLoS ONE 10(6): e0128226. https://doi.org/10.1371/journal.pone.0128226


# First transform variables for model
centroid_monthly <- centroid_monthly %>%
                   mutate(TotalVisitorsLog = log(TotalVisitors),
                          y = year(ym), 
                          m = month(ym)) 


monthly_proportion <- centroid_monthly %>%
  dplyr::filter(y < 2024) %>%
  group_by(y) %>%
  mutate(vis_sum = sum(TotalVisitors, na.rm = TRUE),
         monthly_prop = TotalVisitors/vis_sum,
         tavg_c = (tavg_f - 32)*5/9) 

ggplot(monthly_proportion) + geom_boxplot(aes(x = floor(tavg_c), y = monthly_prop, group = floor(tavg_c))) + 
  labs(x = "Monthly Temperature (C)", y = "Monthly visitation (proportion)", title = "BRCA" )


visitor_mlr = lm(formula = TotalVisitorsLog ~ 
                    tavg_f +
                    days_gt_77F +
                    y,
                 data = centroid_monthly %>%
                   filter(year(ym) <= 2023))

print(summary(visitor_mlr))

centroid_monthly <- centroid_monthly %>%
  cbind(., predict(visitor_mlr, centroid_monthly, interval = "confidence") %>%
          `colnames<-`(c( "TotalVisitors_mlr_fit", 
                          "TotalVisitors_mlr_lwr",
                          "TotalVisitors_mlr_upr"))) %>%
  mutate(TotalVisitors_mlr_fit = TotalVisitors_mlr_fit %>% exp(),
        TotalVisitors_mlr_lwr = TotalVisitors_mlr_lwr %>% exp(),
        TotalVisitors_mlr_upr = TotalVisitors_mlr_upr %>% exp())


ggplot(centroid_monthly %>% filter(year(ym)<2070)) + 
  geom_line(aes(x = ym, y = TotalVisitors_mlr_fit, color = cf), size = .5) +
  geom_ribbon(aes(x = ym, ymin = TotalVisitors_mlr_lwr, ymax = TotalVisitors_mlr_upr),alpha = 0.5) +
  geom_line(aes(x = ym, y = TotalVisitors,color = "historical_actual"), size = .5) + 
  scale_color_manual("",values = c("darkgray","black","darkred","cornflowerblue"), 
                     labels = c("Historical MLR Fit","Historical Actual","Hot Dry", "Warm Wet" )) #+ xlim(as.Date("1980-01-01"), as.Date("2023-01-01")) +
  #ylim(0,650000) +
  labs(x = "", y = "Total Monthly Visitors", title = "BRCA") + 
  theme_bw()# + coord_trans(y = "log10") 

# Consolidate to annual sum
proj_visitor_annual <- centroid_monthly %>%
  dplyr::select(-c(ym,gcm,unit_climate_zone)) %>%
  group_by(y,cf) %>%
  dplyr::summarize(TotalVisitors_mlr_fit = sum(TotalVisitors_mlr_fit, na.rm = FALSE),
            TotalVisitors_mlr_lwr = sum(TotalVisitors_mlr_lwr, na.rm = FALSE),
            TotalVisitors_mlr_upr = sum(TotalVisitors_mlr_upr, na.rm = FALSE),
            .groups = "keep")

# Append to annual dataset
centroid_annual <- centroid_annual %>%
  left_join(.,proj_visitor_annual, by = c("y","cf") )


# 3. Use projected visitation to repeat 10 year mean calculations 
# With 95% confidence intervals now
visitor_2053_mean <- centroid_annual %>%
  ungroup() %>%
  filter(y > 2043 & y <= 2053) %>%
  dplyr::select(c(TotalVisitors_mlr_fit, 
                  TotalVisitors_mlr_lwr, 
                  TotalVisitors_mlr_upr)) %>%
  summarize_all(mean)

# And percent change from 2013-2023
visitor_future_increase <- (100 * (visitor_2053_mean - visitor_2023_mean) / 
  visitor_2023_mean) %>%
  round(., digits = 0)
                              
################################## DEMAND STATS ################################
# 1. Calculate average demand per visitor for the last 10 years of data

# Average demand per visitor
# Using monthly mean
avg_demand_per_visitor_monthly <- centroid_monthly %>%
  filter(year(ym) > 2012 & year(ym) < 2023) %>%
  dplyr::select(c(ym,demand_pp_af,demand_pp_gal)) %>%
  dplyr::summarize(mean_af = mean(demand_pp_af, rm.na = TRUE),
                  mean_gal = mean(demand_pp_gal, rm.na = TRUE))

# Using annual mean
avg_demand_per_visitor_annual <- centroid_annual %>%
  filter(y > 2012 & y < 2023) %>%
  ungroup() %>%
  dplyr::select(c(demand_pp_af,demand_pp_gal)) %>%
  dplyr::summarize(mean_af = mean(demand_pp_af, rm.na = TRUE),
                  mean_gal = mean(demand_pp_gal, rm.na = TRUE))



# 2. Develop models to predict future water demand per person - 
# First create calibrated model with historic data then project.

# KEC = for now, skip this model - not as good as mlr
# A. Asymptotic Regression based on historic and projected visitation
# Try asymptotic regression equation because plot of monthly visitors (x-axis) 
# vs monthly water use (y-axis) produces exponentially increasing relationship
# that approaches stable value (asymptote) f(x)=c+(dâc)(1âexp(âx/e))

#demand_AR_model <- drm(use_acre_feet ~ TotalVisitors, 
#                       fct = AR.3(), 
#                       type = "continuous",
#                       data = centroid_monthly %>%
#                              filter(year(ym) < 2023) %>%
#                              mutate(use_acre_feet = 
#                                ifelse(use_acre_feet == 0, NA, use_acre_feet)))

#ar_fun<- function(x,c,d,e) {
#  f <- c + (d - c) * (1 - exp(-x / e))
#}

#centroid_monthly <- 
#  mutate(centroid_monthly,
#            AR_demand = ar_fun(centroid_monthly$TotalVisitors,
#                             demand_AR_model$fit$par[1],
#                             demand_AR_model$fit$par[2],
#                             demand_AR_model$fit$par[3]))

#print(summary(demand_AR_model))

#plot(demand_AR_model,log="",xlab = "Total Visitors", ylab = "Monthly Water Demand (af)")

# Next try multiple linear regression which uses multiple inputs
demand_mlr_model = lm(formula = use_acre_feet ~ 
                    tavg_f +
                     # y +
                   TotalVisitors +
                     aet_in +
                     precip_in,
                 data = centroid_monthly %>%
                              filter(year(ym) < 2023) %>%
                              mutate(use_acre_feet = 
                                ifelse(use_acre_feet == 0, NA, use_acre_feet)))

print(summary(demand_mlr_model))

centroid_monthly <- 
  mutate(centroid_monthly,
            MLR_demand_fit = predict(demand_mlr_model, centroid_monthly),
            MLR_demand_lwr = predict(demand_mlr_model, centroid_monthly, interval = "confidence")[,2],
            MLR_demand_upr = predict(demand_mlr_model, centroid_monthly, interval = "confidence")[,3])

# Plot monthly models
ggplot(centroid_monthly %>% filter(y < 2024)) + 
  geom_line(aes(x = ym, 
                y = use_acre_feet,
             color = "Actual Use"), size = .5) +
geom_line(aes(x = ym, 
              y = MLR_demand_fit,
             color = "MLR Model"),size = .5) +
geom_ribbon(aes(x = ym, ymin = MLR_demand_lwr,
                ymax = MLR_demand_upr), fill = "dodgerblue", alpha = .6) +
#geom_line(aes(x = ym,
#              y = AR_demand,
#              color = "AR Model"), size = 1) + 
  scale_color_manual("", values = c("black","dodgerblue")) +
  labs(x = "", y = "Monthly Water Demand (af)") + theme_bw()



# How does it do for annual predictions
demand_annual <- centroid_monthly %>%
  dplyr::select(c('y','use_acre_feet','MLR_demand_fit','cf')) %>%
  group_by(y,cf) %>%
  summarize_all(list(sum))

# Doesn't do great for annual water use -- so develop annual model
ggplot(demand_annual %>% 
         pivot_longer(cols = -c(y,cf), names_to = 'vars', values_to = 'vals'),
         aes(x = y, y = vals, color = vars)) + 
  geom_line(size = 1) + 
  scale_color_manual("", values = c("dodgerblue","hotpink","black")) +
                         #labels = c("AR Model","MLR Model","Actual")) + 
  labs(y = "Annual Water Use (af)", title = "Monthly Model")


# What if instead you calibrate the model to annual data

# Develop model to predict future water use - 
# First create calibrated model using historic data

# Again, don't do AR model for now
#demand_AR_modelA <- drm(use_acre_feet ~ TotalVisitors, 
#                       fct = AR.3(), 
#                       type = "continuous",
#                       data = centroid_annual %>%
#                              filter(y < 2023) %>%
#                              mutate(use_acre_feet = 
#                               ifelse(use_acre_feet == 0, NA, use_acre_feet)))
#ar_fun<- function(x,c,d,e) {
#  f <- c + (d - c) * (1 - exp(-x / e))
#}
#centroid_annual_historic <- 
#  cbind(centroid_annual_historic,
#            AR_demand = ar_fun(centroid_annual_historic$TotalVisitors,
#                             demand_AR_modelA$fit$par[1],
#                             demand_AR_modelA$fit$par[2],
#                             demand_AR_modelA$fit$par[3]))
#print(summary(demand_AR_model))


# multiple linear regression
demand_mlr_modelA = lm(formula = use_acre_feet ~ 
                    tavg_f +
                   TotalVisitors+
                     aet_in +
                     precip_in,
                 data = centroid_annual %>%
                        filter(y < 2023) %>%
                        mutate(use_acre_feet = 
                            ifelse(use_acre_feet == 0, NA, use_acre_feet)))


centroid_annual <- centroid_annual %>%
  mutate(MLR_demandA_fit = predict(demand_mlr_modelA, newdata = centroid_annual),
         MLR_demandA_lwr = predict(demand_mlr_modelA, newdata = centroid_annual, interval = "confidence")[,2],
         MLR_demandA_upr = predict(demand_mlr_modelA, newdata = centroid_annual, interval = "confidence")[,3])

# Plot monthly models
ggplot(centroid_annual) + 
  geom_line(aes(x = y, y = use_acre_feet,
             color = "Actual Use"), size = 1) +
geom_line(aes(x = y, 
              y = MLR_demandA_fit,
             color = "MLR Model"), size = 1) +
#geom_line(aes(x = y,
#              y = AR_demand,
#              color = "AR Model"), size = 1) + 
  scale_color_manual("", values = c("black","dodgerblue")) +
  labs(x = "", y = "Annual Water Use", title = "Annual Model") + theme_bw()


# Now make predictions

temp_centroid_annual <- centroid_annual %>%
  mutate(TotalVisitors = TotalVisitors_mlr_fit)

# Predict using updated model

centroid_annual <- centroid_annual %>%
  mutate(MLR_demandAp_fit = predict(demand_mlr_modelA, newdata = temp_centroid_annual),
         MLR_demandAp_lwr = predict(demand_mlr_modelA, temp_centroid_annual, interval = "confidence")[,2],
         MLR_demandAp_upr = predict(demand_mlr_modelA, temp_centroid_annual, interval = "confidence")[,3],
         PP_demand = TotalVisitors_mlr_fit*avg_demand_per_visitor_annual$mean_af,
         PP_demand_lwr = TotalVisitors_mlr_lwr*avg_demand_per_visitor_annual$mean_af,
         PP_demand_upr = TotalVisitors_mlr_upr*avg_demand_per_visitor_annual$mean_af)

ggplot(centroid_annual) +
  geom_line(aes(x = y, y = MLR_demandAp_fit, color = "MLR Demand")) +
  geom_ribbon(aes(x = y, ymin =  MLR_demandAp_lwr, ymax =  MLR_demandAp_upr, 
              color = "MLR Demand"), alpha = 0.2, linewidth = 0,
              fill = "dodgerblue") + 
  #geom_line(aes(x = y, y = PP_demand, color = "PP Demand")) +
  #  geom_ribbon(aes(x = y, ymin = PP_demand_lwr, ymax = PP_demand_upr,
  #              color = "PP Demand"), alpha = 0.2, linewidth = 0,
  #              fill = "seagreen") + 
  geom_line(aes(x = y, 
                y = use_acre_feet,
                color = "Historic")) + 
  scale_color_manual("", values = c("black","dodgerblue")) +
  #scale_fill_manual("", values = c("hotpink","black","dodgerblue","seagreen")) +
  labs(x = "", y = "Annual Water Demand (af)") + 
  xlim(1980,2080) + ylim(-100,350) + theme_bw()
  
rm(temp_centroid_annual)

# KEC -- looking at this plot, the MLR (and both models really) perform decently
# for seasonal trends in visitation but miss "high-use" months. After talking 
# with park managers for BRCA, this may be due to things like leaks in the 
# system, large construction projects, and other "unpredictable" events that may 
# happen with some quantifiable recurrance interval but may not have another 
# explanatory variable. Just a thought for now.

############################# Vulnerability ####################################

#water vulnerability is an imbalance between the supply and demand of water 
# resources within a region over a certain time.
  


```

# Generate some report variables
```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

report_name <- paste0("Climate Change Vulnerability Assesment for Water Supplies at ",park_name)


```


Save data

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

save_variables <- ls() 
                   # Update to include select variables only in future... e.g.,
                  # c(park, spring_precip_yearly_change, fall_precip_yearly_change)

## path to data folder (from project directory)
out_path <- paste0("data/park/",park,"/",park,"_report_data.RData")

save(save_variables, 
     file = out_path)


```

## Examples

1.  Example maps

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}
# Optional view data

mapviewOptions(basemaps = c("Esri.WorldStreetMap", "Esri.WorldImagery","Esri.WorldShadedRelief"))

pal = colorRampPalette(c("dodgerblue4","dodgerblue", "white","pink","red"))

#mapview(koppen_park,
#        zcol = "K_vals",
#        #aes(color = color),
#        col.regions = koppen_park$color %>% unique(),
#        #at = koppen_park$K_vals %>% unique(),
#        alpha = 0,
#        homebutton = FALSE,
#        layer.name = "Koppen") +
  mapview(park_boundary, 
        col.regions = "#74a089", 
        alpha.regions = .5, 
        lwd = 2, 
        #popup = FALSE, 
        #legend = F, 
        homebutton = FALSE,
        layer.name = paste0(park," Park Boundary")) +
  mapview(park_watershed,
          col.regions= NA, 
          alpha.regions = 0, 
          lwd = .25, 
          popup = FALSE, 
          legend = FALSE, 
          homebutton = FALSE,
          label = FALSE) +
  mapview(park_flowlines,
          col.regions = "darkblue",
          lwd = 0.5,
          popup = FALSE, 
          legend = FALSE, 
          homebutton = FALSE,
          label = FALSE) +
  # UNCOMMENT IF AVAILABLE
  mapview(dplyr::summarize(watersupply_watershed),
          col.regions = "#E69F00", 
          alpha.regions = .5, 
          #popup = FALSE, 
          #legend = F, 
          homebutton = FALSE,
          layer.name = "Water Supply Watershed",
          legend = FALSE) +
  mapview(watersupply_flowlines,
          col.regions = "darkblue",
          lwd = 0.5,
          popup = FALSE, 
          legend = FALSE, 
          homebutton = FALSE,
          label = FALSE) +
    mapview(nwis_groundwater,
            cex = 6,
            col.regions = c("#8C86A0"),
            label = FALSE,
            homebutton = FALSE,
            layer.name = "NWIS Wells") +
  mapview(nldi_watershed,
          col.regions= NA, 
          alpha.regions = 0, 
          lwd = .5,
          color = "#C0532B",
          popup = FALSE, 
          legend = FALSE, 
          homebutton = FALSE,
          label = FALSE) +
  mapview(POD_supply,
          col.regions = c("#E69F00"), # orange
          alpha.regions = 1,
          alpha = 1,
          cex = 6, 
          layer.name = "Park Water Supply & Watershed",
          homebutton = FALSE,
          label = FALSE) +
  mapview(nwis_stream,
            cex = 6,
            col.regions = c("#C0532B"),
            homebutton = FALSE,
            layer.name = "NWIS Stream Gages & watersheds") + 
mapview(st_as_stars(diff_30y),
        alpha.regions = 0.5,
        col.regions = pal(20), 
        at = seq(-1,1,.1),
        na.color = NA,
        layer.name = "Runoff Change") + 
  mapview(park_boundary,
          alpha.regions = 0,
          color = "black",
          lwd = 3,
          trim = TRUE)
  mapview(nldi_watershed)


  #mapview(koppen_cent,
  #        layer.name = "Centroids")

color_list = c("#882314", "#C0532B", "#CF932C", "#674D53", "#8C86A0", "#724438",
               "#D5AB85","#01353D", "#088096", "#58B3C7", "#7AD4E4", "#B8FCFC",
               "#293633", "#3D5051", "#6B7F7F", "#87A1C7", "#516B95", "#304F7D",
               "#0067A2", "#DFCB91", "#CB7223", "#289A84", "#7FA4C2", "#AF7E56")

```

2.  Example Tables

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# kable tips:
# https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html

df <- annual_stats %>%
        dplyr::select(
          cf = cf, 
          AET = aet_in_mean,
          Runoff = runoff_in_mean,
          "Runoff Variability" = runoff_in_sd,
          "Days > Hist 95th <br> Percentile Runoff" = days_gt_95roff_mean,
          "Days Precip" = days_w_pcp_mean,
          "Days SWE" = days_w_swe_mean) %>%
        mutate_if(is.numeric, round, digits = 3) %>%
        t() %>% 
        as.data.frame() %>%
        janitor::row_to_names(row_number = 1) %>% 
        dplyr::select(c("Historical","Hot Dry", "Hot Wet", "Warm Dry", "Warm Wet"))



kable(df, digits = 2, escape = FALSE, booktabs = T) %>%
  kable_styling() %>%
kableExtra::landscape() %>%
  #kable_styling(full_width = F) %>%
    kable_paper(full_width = F)
```

3.  Example Timeseries

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

ggplot(centroid_annual %>% filter(y < 2071), #%>% filter(y < 2010 | y > 2050),
       aes(x = y, y = runoff_in * 0.0254 * as.numeric(st_area(park_boundary)) * 0.000810714, 
           color = as.factor(cf))) + 
#  geom_violin() + 
#  geom_boxplot(width = 1) +
  #geom_point() +
  geom_line()+
  geom_smooth(aes(fill = as.factor(cf)),span = 3) +
   labs(x = "year", y = "Annual Runoff (acre-feet)") + 
  scale_color_manual("",values = c("gray40","darkred","cornflowerblue","pink","navy")) +
  scale_fill_manual("",values = c("gray40","darkred","cornflowerblue","pink","navy"))
  #facet_wrap(~season, scales = "free")
```

Trends in the date of maximum runoff

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}
a <- ggplot(max_annual_runoff %>% filter(season == "Spring" | season == "Winter"),
       aes(x = year(Date), y = doy, color = cf)) + 
  geom_point() +
  geom_smooth(method = lm) + 
  labs(x = "", y = "Day of maximum annual spring runoff") + 
  scale_color_manual("",values = c("black","darkred","dodgerblue"))

b <- ggplot(max_annual_runoff %>% filter(season == "Summer" | season == "Fall"),
       aes(x = year(Date), y = doy, color = cf)) + 
  geom_point() +
  geom_smooth(method = lm) + 
  labs(x = "", y = "Day of maximum annual spring runoff") + 
  scale_color_manual("",values = c("black","darkred","dodgerblue"))

ggarrange(a,b,ncol = 1)
```

Histograms of the day-of-year of maximum annual runoff

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}
ggplot(max_annual_runoff,aes(x = doy, fill = cf)) + geom_histogram() +
  scale_fill_manual("",values = c("black","darkred","dodgerblue")) +
  facet_wrap(~cf)
```

# Plot visitor trends

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}
ggplot() +
  geom_point(aes(x = visitors_annual$year, 
          y = visitors_annual$TotalVisitors)) + 
  stat_smooth(aes(x = visitors_annual$year, 
          y = visitors_annual$TotalVisitors,col = "Historic"), 
          method = "lm",linetype = "dashed") +
  geom_line(aes(x = visitors_proj$year, y = visitors_proj$p[,1], 
                col = "projected"),
             linetype = "dashed", size = 1) +
  geom_ribbon(aes(x = visitors_proj$year, ymin = visitors_proj$p[,2], 
              ymax = visitors_proj$p[,3], color = "projected"),fill = "dodgerblue", alpha = 0.2, linewidth = 0) +
  labs(x = paste("Year\n\nAdj R2 = ",signif(summary(visitor_trend)$adj.r.squared, 5),
                     " Slope =",signif(visitor_trend$coef[[2]], 5),
                     " P =",signif(summary(visitor_trend)$coef[2,4], 5)),
        y = "Annual Visitors") +
  theme_minimal() + 
  scale_color_manual("",values = c("black","dodgerblue4"))
```
