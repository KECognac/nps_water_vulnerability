---
title: "Generic_CCVA"
author: "KEC"
date: "2024-04-04"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
source('setup.R')
# add rvest to setup
library(rvest)
```

## CCVA Data Processing

This document prepares data inputs for the Water Supply CCVA for a National Park.

## User Input

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# Identify park by 4 digit code 
# (https://www.nps.gov/aboutus/foia/upload/NPS-Unit-List.xlsx)
park <- "BRCA"

```

## Download data

Download necessary data from publicly available sources.

##### Park boundary, watersheds and NHD flowlines

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# Get park boundary
park_boundary <- getParkBoundary(park = park)

# Get watersheds within park boundary
park_watershed <- getWatersheds(aoi = park_boundary, 
                                save = FALSE)

# Get flowlines within park boundary
park_flowlines <- park_watershed %>%
            dplyr:: summarize() %>%
            mapNHDPlusHR() %>%
            dplyr:: summarize()

```

##### Points of diversion and water supply for park

Park water supplies may be sourced from within or beyond the park boundary. This chunk pulls in state-reported water supply locations that occur within a buffer distance from both the park boundary. It also pulls in the watersheds that intersect with those points. Because water supply locations are reported by state, state-specific functions are utilized.

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# ****KEC: This should be nested into a getPODall function with aoi and dist
# args which then applies the state-specific function.

# Get state specific points of diversion (POD) (i.e., water supply points)
buffer_dist <- 0.1 # in decimal degrees lat/long

# State specific functions - need to make for rest of states
if (park_boundary$STATE == "AL") {}

if (park_boundary$STATE == "CA") {
  POD_state <- getPODCalifornia(aoi = park_watershed, 
                                dist = buffer_dist)
} else if (park_boundary$STATE == "NV") {
  POD_state <- getPODNevada(aoi = park_watershed, 
                            dist = buffer_dist)
} else if (park_boundary$STATE == "UT") {
  POD_state <- getPODUtah(aoi = park_watershed, 
                          dist = buffer_dist)
} 

# Now, if POD are available, identify potential water supply from those 
# state-wide PODs.
#         - For some parks, the water supply ID is known.  Select the known
#           supply by ID for those parks.
#         - Where it is unknown, assume the water supply is any POD owned by
#           NPS and located within the buffer distance.

# ****KEC: This assumes POD_state has "OWNER" column and that NPS is identified 
# by string "NATIONAL PARK". Should probably update match strings in future as 
# other POD databases are brought in. 

# ****KEC: Do we keep irrigation, stockwatering, and/or power supply wells?

if (!is_empty(POD_state)) {
# Utah col descriptions for POD_supply 
#.  -> https://www.arcgis.com/sharing/rest/content/items/5d530e62e6ca42528dd13e0a453a3b73/info/metadata/metadata.xml?format=default&output=html
# Some states have a known supply. If so, assign.
if (park == "BRCA") {
    POD_supply <- POD_state %>%
    dplyr::filter(WRNUM %in% c("61-893", "2061001M00")) %>%
    dplyr::distinct(LOCATION, .keep_all = TRUE)
} else {
    POD_supply <- POD_state %>%
    dplyr::filter(OWNER %like% "NATIONAL PARK",
                  #USES %in% c("D","M","MO"),
                  str_detect(USES,"D|M|O")) %>% # municipal, domestic, or other
    dplyr::distinct(LOCATION, .keep_all = TRUE) %>%
      dplyr::distinct(WRNUM, .keep_all = TRUE)
}

# Get watershed intersecting each watersupply point
watersupply_watershed <- vector("list", nrow(POD_supply))  
  
for(i in 1:nrow(POD_supply)){
  watersupply_watershed[[i]] <- POD_supply[i,] %>% 
  getXYWatersheds(sf = ., coordinates = NULL)
}

watersupply_watershed <- watersupply_watershed %>%
  dplyr::bind_rows() %>% 
  dplyr::distinct(featureid, .keep_all = TRUE) 

# Get flowlines associated with watersupply watershed
watersupply_flowlines <- watersupply_watershed %>%
              dplyr::summarize() %>%
              mapNHDPlusHR()
}


```

##### Centroids

Climate futures have been previously compiled for park and Koppen centroids. Check which of these best represents conditions at the (potential) source(s) for the park's water supply.

Source for Koppen-Geiger climate classification maps:

Beck, H. E., Zimmermann, N. E., McVicar, T. R., Vergopolan, N., Berg, A., & Wood, E. F. (2018). Present and future KÃ¶ppen-Geiger climate classification maps at 1-km resolution. Scientific data, 5(1), 1-12.

 https://figshare.com/articles/dataset/Present_and_future_K_ppen-Geiger_climate_classification_maps_at_1-km_resolution/6396959/2


#### First get Koppen climate data for park

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# Get koppen climate grid for park with buffer
koppen_park <- get_koppen(aoi = park_boundary, 
                             buffer_dist = 0.1)


# Get koppen climate intersecting watershed
# create a merged watersupply watershed for subsequent functions
ws_union <- sf::st_union(watersupply_watershed) %>%
            sf::st_as_sf()

koppen_ws <- get_koppen(aoi = ws_union, 
                           buffer_dist = 0) %>%
            sf::st_transform(., crs = sf::st_crs(ws_union)) %>%
            dplyr::filter(st_intersects(., ws_union) %>% 
            as.logical())
            

# Create a table of Koppen and park centroids with area span for each koppen
# climate that overlaps with watersupply watershed (from above) and distance
# between centroid location and watersupply watershed. 

#****KEC:  Note, nothing is done with this as of now, but we can incorporate 
#* later

centroid_sel <- 
  # get table of koppen centroids from web
  GET('https://parkfutures.s3.us-west-2.amazonaws.com/maca-tprh-data/0Climate_Zones_by_Unit_cleaned.csv') %>% 
            as.character() %>% 
            data.table::fread(.,header = TRUE, skip = 1) %>%
            dplyr::filter(UNIT_CODE == park) %>%
            sf::st_as_sf(coords = c("Lon","Lat"), 
                        crs = sf::st_crs(watersupply_watershed)) %>%
            # Calc. distance between centroid and watersupply watershed
            dplyr::mutate(dist = (sf::st_distance(geometry,ws_union))) %>%
            # Add park centroid point
            bind_rows(sf::st_centroid(park_boundary) %>% 
                      st_as_sf() %>%
                      dplyr::mutate(dist = (sf::st_distance(Shape, ws_union)))) %>%
            sf::st_set_geometry(., NULL) %>%
            # Clean some metadata / cols
            dplyr::select(c(ClimateZone,dist)) %>%
            dplyr::mutate(CZ_str = sprintf("_%02d", ClimateZone),
                          CZ_str = str_replace(CZ_str, "_NA", ""),
                          centroid = paste0(park,CZ_str)) %>%
          dplyr::left_join(koppen_ws %>% dplyr::count(K_vals), 
                           by = c("ClimateZone" ="K_vals")) %>%
          dplyr::select(-CZ_str)

# Pull centroid with minimum distance to watersupply watershed
min_dist_cent <- centroid_sel[which.max(centroid_sel$n),]$centroid
# Pull centroid corresponding to maximum overlap with watersupply watershed
max_overlap_cent <- centroid_sel[which.max(centroid_sel$n),]$centroid



```

#### Get Climate data for park centroid

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# Import table of selected futures for site. Selections were made using the "select_GCMs" 
# function. 
select_cfs <- data.table::fread('data/parkwide_GCMs.csv') %>% 
              mutate_at("centroid", str_replace, "_future", "") %>%
              dplyr::filter(park %in% {{park}}) %>%
              # Uncomment either:
              # a. if using min distance to supply watershed 
              dplyr::filter(centroid == min_dist_cent)
              # or b.if using max overlap with supply watershed
              #dplyr::filter(centroid == max_overlap_cent)

# replacement for now until selection is fixed
select_cfs[select_cfs$GCM=="MIROC-ESM.rcp85",]$GCM <- "MIROC-ESM-CHEM.rcp85"

# ****KEC: update function to check if files exist before downloading.
get_centroid_climate_data(park = park, save = TRUE)

# Directory to which files were downloaded.
climate_dir <- paste0("data/park/",park,"/centroid/climate")

# Import centroid climate data
centroid_climate <- base::list.files(climate_dir,full.names = TRUE) %>%
            purrr::map(~ read_csv(.x) %>% 
            dplyr::mutate(Unit_ClimateZone = str_remove_all(basename(.x),
                              "_(?<=_)(future|historical)\\.csv"))) %>%
            dplyr::bind_rows() %>%
            dplyr::left_join(select_cfs, by = "GCM") %>%
            dplyr::mutate(CF = ifelse(GCM %in% "gridmet.historical","Historical",CF)) %>%
            janitor::clean_names() %>%
            dplyr::select(-c(park, delta_tavg,delta_pr)) %>%
            dplyr::filter(unit_climate_zone == select_cfs$centroid[1])


```

#### WBM Data

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# Download centroid data -- will need to update for each park
get_centroid_wbm_data(park = park)
    
## Note, currently getting an error with save = FALSE in function call

wbm_dir <- paste0("data/park/",park,"/centroid/wbm/")

centroid_wbm <- list.files(wbm_dir,full.names = TRUE) %>% 
            purrr::map(~ read_csv(.)) %>% 
            bind_rows() %>%
            left_join(select_cfs, by = "GCM") %>%
            dplyr::mutate(CF = ifelse(GCM %in% "gridmet.historical","Historical",CF)) %>%
            janitor::clean_names() %>%
            dplyr::select(-c(park,lat,lon,delta_tavg,delta_pr, period)) %>%
            dplyr::filter(unit_climate_zone == select_cfs$centroid[1])

```

#### Water use data

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# Get state specific water use data --> in monthly format

if (park_boundary$STATE == "UT") {

  water_supply_id <- getWaterSuppliersUtah(aoi = park_boundary) %>%
    filter(grepl("National Park", WRNAME, ignore.case=TRUE)) %>%
    .$WRID

  # Park specific selections based on known ID
  
  if (park == "BRCA") {
    
    water_use_1 <- getWaterUseUtah(WRID = water_supply_id)[[1]] %>%
                  slice(1:39) %>%
                  pivot_longer(-c("Year", "Method of Measurement"), 
                               names_to = "month", 
                               values_to = "use_acre_feet") %>%
                  dplyr::mutate(ym = ym(paste0(Year, "-", month))) %>%
                  dplyr::filter(month != "Annual inAcre Feet") %>%
                  dplyr::select(ym, use_acre_feet) %>%
                  dplyr::mutate(well = "Well 1")
  
  # Well 2
  water_use_2 <- getWaterUseUtah(WRID = water_supply_id)[[1]] %>%
                  slice(51:nrow(.)) %>%
                  dplyr::filter(!is.na(as.numeric(Year))) %>%
                  pivot_longer(-c("Year", "Method of Measurement"), 
                               names_to = "month", 
                               values_to = "use_acre_feet") %>%
                  dplyr::mutate(ym = ym(paste0(Year, "-", month))) %>%
                  dplyr::filter(month != "Annual inAcre Feet") %>%
                  dplyr::select(ym, use_acre_feet) %>%
                  dplyr::mutate(well = "Well 2")
  
  # join water use data
  water_use <- water_use_1 %>%
              dplyr::bind_rows(water_use_2) %>%
              dplyr::group_by(ym) %>%
              dplyr::summarize(use_acre_feet = sum(as.numeric(use_acre_feet), 
                                                   na.rm = TRUE))
  
    rm(list = c("water_use_1", "water_use_2"))
  
  } else {
    
  # For UTAH parks without specific info on # of wells, etc, sum all
  # use for each month.
  water_use <- getWaterUseUtah(WRID = water_supply_id)[[1]] %>%
                dplyr::filter(!is.na(suppressWarnings(as.numeric(Year)))) %>%
                tidyr::pivot_longer(-c("Year","Method of Measurement"), 
                             names_to = "month", 
                             values_to = "use_acre_feet") %>%
                dplyr::filter(month != "Annual inAcre Feet") %>%
                dplyr::mutate(ym = ym(paste0(Year, "-", month))) %>%
                dplyr::group_by(ym) %>%
                dplyr::summarize(use_acre_feet = sum(as.numeric(use_acre_feet), 
                                                     na.rm = TRUE)) 
  }

}



```

##### USGS gages within the park or POD watershed

For many parks, the nearest USGS stream gage is far away. Therefore, we are pulling all NWIS gages within 100 km of the park boundary. Of those, we only select stream gages that are considered "reference" gages in the [GAGES-II database (Falcone, 2011)](https://pubs.usgs.gov/publication/70046617). Then, we delineate each of those gages' watersheds using the `get_nldi_basin()` function from the {nhdplusTools} package:

```{r, eval = TRUE, message = FALSE, warning = FALSE}

# Get all NWIS sites
nwis <- listNWIS(aoi = watersupply_watershed %>% dplyr::summarize(), dist = .3) #%>%


  #dplyr::filter(data_type_cd == "dv",
  #       code == "00060")

# Get NWIS Stream Gages
ref_gages <- get_gagesII(id = nwis$site_no) %>%
             dplyr::filter(class == "Ref")

nwis_stream <- nwis %>%
              dplyr::filter(site_no %in% ref_gages$staid,
                            data_type_cd == "dv") %>%
              dplyr::left_join(st_drop_geometry(ref_gages), 
                               by = c("site_no" ="staid")) 

# Download data from reference stream sites
nwis_stream_discharge <- 
  dataRetrieval::readNWISdv(siteNumbers = nwis_stream$site_no,
                            parameterCd = c('00060','00065')) %>%
    dplyr::mutate(y = year(Date), m = month(Date)) %>%
    dplyr::filter(y >= 1980) %>%
    dplyr::group_by(y,m, site_no) %>%
    dplyr::summarize(mean_discharge = mean(X_00060_00003, na.rm. = TRUE),
                     .groups = "keep") %>%
    dplyr::ungroup() %>%
    dplyr::mutate(ym = lubridate::make_date(year = y, month = m, day = 1)) %>% 
    dplyr::select(ym, site_no, mean_discharge) %>%
    tidyr::pivot_wider(names_from = site_no, 
                       names_prefix = "gage_", 
                       values_from = mean_discharge) #%>%

# Download data from reference stream sites
#getNWIS(inventory = nwis_stream, park = "misc", path = "data/")


# Define functions to get those watersheds for ref. gages using get_nldi_basin 
# in from {nhdplusTools}.

# ================ Function to identify NLDI watersheds ========================

nldi_finder <- function(site_no) {
  
  nldi_nwis <- list(featureSource = "nwissite",
                    featureID = paste0("USGS-", site_no))
  
  gage_basin <- nhdplusTools::get_nldi_basin(nldi_feature = nldi_nwis) %>%
                              st_transform(., 4269) %>%
                              dplyr::mutate(site_no = site_no) %>%
                              suppressMessages() %>%
                              invisible()
  
  return(gage_basin)
  
}


# ================ Function to identify NLDI metadata ==========================

nldi_meta <- function(site_no){
  
  nldi_nwis <- list(featureSource = "nwissite",
                    featureID = paste0("USGS-", site_no))
  
  gage_basin <- nhdplusTools::get_nldi_characteristics(nldi_feature = nldi_nwis,
                                                       type = "total")[[1]] %>%
                dplyr::filter(characteristic_id %in% 
                        c("TOT_ELEV_MEAN", "TOT_ELEV_MAX", "TOT_ELEV_MIN")) %>%
                tidyr::pivot_wider(-percent_nodata, 
                                   values_from = characteristic_value, 
                                   names_from = characteristic_id)
  return(gage_basin)
  
}


# Now, use functions to get watersheds associated with stream gages
nldi_watershed <- nwis_stream$site_no %>%
                purrr::map_dfr(~nldi_finder(site_no = .)) %>%
                dplyr::mutate(data = map(site_no, ~nldi_meta(site_no = .))) %>%
                unnest() %>%
                dplyr::left_join(st_drop_geometry(nwis), by = "site_no")

nldi_flowlines <- dplyr::summarize(nldi_watershed) %>%
                  mapNHDPlusHR() %>% 
                  dplyr::summarize()


# Now Get Gw sites

nwis_groundwater <- nwis %>%
  dplyr::filter(begin_date != end_date,
         n_obs > 50,
         # groundwater sites only:
         site_type_cd == "GW",
         data_type_cd == "gw",
         code == 72019) %>%
  dplyr::mutate(dist = st_distance(geometry,park_boundary) %>%
                  as.numeric()) %>%
         dplyr::filter(dist <= 1600*3) %>%
  add_gw_meta()


# pull those sites groundwater level data
  nwis_groundwater_levels <- dataRetrieval::readNWISgwl(nwis_groundwater$site_no) %>%
    dplyr::filter(parameter_cd == 72019,
                  year(lev_dt) >= 1980) %>% # 72019 =Depths, 62611=elevation
    dplyr::mutate(ym = lubridate::ym(substr(lev_dt, 1, 7))) %>% 
    dplyr::group_by(ym, site_no) %>%
    dplyr::summarize(mean_lev_va = mean(lev_va, na.rm. = TRUE)) %>%
    dplyr::select(ym, site_no, mean_lev_va) %>%
    tidyr::pivot_wider(names_from = site_no, names_prefix = "well_", values_from = mean_lev_va) #%>%


```

#### Park Visitation

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}
# NPS monthly visitor information
visitors <- 
  getUnitVisitation(units = park, startYear = 1980, endYear = 2023) %>%
  dplyr::mutate(ym = ym(paste0(Year, "-", Month))) %>%
  dplyr::mutate(TotalVisitors = RecreationVisitors + NonRecreationVisitors) %>%
  dplyr::select(ym, RecreationVisitors, TotalVisitors)




```

## Begin data analysis

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

## THis section is a WORK IN PROGRESS

# Now join all centroid datasets
centroid_all <- left_join(centroid_climate %>%
                            dplyr::filter(!is.na(cf)), # removes non-selected
                          centroid_wbm %>%
                            dplyr::filter(!is.na(cf)), 
                by = c("date","gcm","cf", "centroid","unit_climate_zone")) 


# Set date range for historic and future aggregation periods
hist_years <- c(1980,2010)      # 30 year
future_years <- c(2040,2070)   # 30 year


# For temporal aggregations, some variables will be summarized using the mean 
# while others will use the sum. Define which cols for subsequent calculations
mean_cols <- c("tavg_f","tmax_f","tmin_f","r_hmax_percent","r_hmin_percent",
               "deficit_in","soil_water_in","runoff_in","accumswe_in")
sum_cols <- c("precip_in","rain_in","aet_in","pet_in","days_gt_92F",
              "days_lt_32F","days_gt_95pcp","days_gt_95roff", "days_lt_05roff",
              "days_w_pcp","days_w_swe")


################################ Daily Stats ###################################

# First, calculate some generic stats on daily data for historic and future
# periods of interest
stats <- centroid_all %>%
  dplyr::mutate(stat_group = 
               dplyr::case_when(year(date) > hist_years[1] & 
                                year(date) < hist_years[2] ~ "Historical",
                                year(date) > future_years[1] & 
                                year(date) < future_years[2] ~ "Future")) %>%
  tidyr::drop_na(any_of("stat_group")) %>%
  dplyr::select(-c(date,gcm,unit_climate_zone,centroid)) %>%
  dplyr::group_by(cf,stat_group) %>%
  dplyr::summarize_all(.funs = 
                        list(Q95 = ~ quantile(., probs = 0.95, na.rm = TRUE),
                             Q05 = ~ quantile(., probs = 0.05, na.rm = TRUE),
                            mean = ~ mean(., na.rm = TRUE),
                          median = ~ median(., na.rm = TRUE),
                              sd = ~ sd(., na.rm = TRUE)),
                       .groups = "keep")


# Now, add binary indicator to get day counts (e.g., 1 for days over X degrees,
# 0 for days under X degrees)
centroid_all <- centroid_all %>%
  group_by(cf) %>%
      # Get day counts for conditional statistics
      dplyr::mutate(days_gt_92F = ifelse(tmax_f > 92, 1,0),
                    days_lt_32F = ifelse(tmin_f < 32, 1,0),
                    days_w_pcp = ifelse(precip_in >0,1,0),
                    days_w_swe = ifelse(accumswe_in >0,1,0),
                  days_gt_95pcp = ifelse(precip_in >= stats[stats$stat_group == 
                                              "Historical",]$precip_in_Q95,1,0),
                 days_gt_95roff = ifelse(runoff_in >= stats[stats$stat_group == 
                                              "Historical",]$runoff_in_Q95,1,0),
                 days_lt_05roff = ifelse(runoff_in <= stats[stats$stat_group == 
                                              "Historical",]$runoff_in_Q05,1,0))


############################## Seasonal Stats ##################################

# Create Seasonal Dataframe
centroid_seasonal <- centroid_all %>%
  dplyr::mutate(season = case_when(month(date) %in% c(12,1,2) ~ "Winter",
                            month(date) %in% c(3,4,5) ~ "Spring",
                            month(date) %in% c(6,7,8) ~ "Summer",
                            month(date) %in% c(9,10,11) ~ "Fall")) %>%
  dplyr::mutate(y = year(date)) %>%
  dplyr::select(-c(date,gcm)) %>%
  dplyr::group_by(y,season,cf)%>%
  dplyr::summarize(
              across(all_of(sum_cols),sum),  # Sum of columns in sum_cols list
              across(all_of(mean_cols),mean),
              .groups = "keep")


hist_95th_pctl_spring_roff <- centroid_seasonal %>% 
                      filter(season == "Spring", 
                             y > hist_years[1] & y < hist_years[2]) %>%
                      pull(runoff_in) %>% 
                      quantile(.95)

seasonal_stats <- centroid_seasonal %>%
  dplyr::mutate(stat_group = 
                  ifelse(y > hist_years[1] & y < hist_years[2], "Historical",
                  ifelse(y > future_years[1] & y < future_years[2], 
                                    "Future",NA))) %>%
  dplyr::ungroup() %>%
  tidyr::drop_na(any_of("stat_group")) %>%
  dplyr::group_by(cf,stat_group,season) %>%
  dplyr::summarize_all(.funs = 
                        list(mean = ~ mean(., na.rm = TRUE),
                          median = ~ median(., na.rm = TRUE),
                              sd = ~ sd(., na.rm = TRUE)),
                       .groups = "keep")
  
############################## Monthly Stats ###################################

# Create Monthly Dataframe
centroid_monthly <- centroid_all  %>%
  # Group and summarize by month and year
            dplyr::mutate(y = year(date), m = month(date)) %>%
            dplyr::select(-c(date)) %>%
            dplyr::group_by(y,m,gcm,unit_climate_zone,cf) %>%
            dplyr::summarize(
              across(all_of(sum_cols),sum),  
              across(all_of(mean_cols),mean),
              .groups = "keep") %>%
            dplyr::mutate(ym = make_date(y,m), .before = gcm) %>%
            dplyr::ungroup() %>%
            dplyr::select(-c(y,m)) %>%
  # Add other monthly datasets to monthly
            dplyr::left_join(nwis_groundwater_levels, by = c("ym")) %>%
            dplyr::left_join(nwis_stream_discharge, by = c("ym")) %>%
            dplyr::left_join(visitors, by = c("ym"))

  
############################### Annual Stats ###################################
  
# Create Annual Dataframe
centroid_annual <- centroid_all  %>%
            dplyr::mutate(y = year(date)) %>%
            dplyr::select(-c(date)) %>%
            dplyr::group_by(y,gcm,unit_climate_zone,cf) %>%
            dplyr::summarize(
              across(all_of(sum_cols),sum),  # Sum of columns in sum_cols list
              across(all_of(mean_cols),mean),
              .groups = "keep") #%>%
                  #dplyr::mutate(y = make_date(y)) 


# Calculate future and historic means for each value.
annual_stats <- centroid_annual %>%
  dplyr::mutate(stat_group = 
                  ifelse(y > hist_years[1] & y < hist_years[2], "Historical",
                  ifelse(y > future_years[1] & y < future_years[2], 
                                    "Future",NA))) %>%
  dplyr::ungroup() %>%
  tidyr::drop_na(any_of("stat_group")) %>%
  dplyr::select(-c(gcm,unit_climate_zone)) %>%
  dplyr::group_by(cf,stat_group) %>%
  dplyr::summarize_all(.funs = 
                        list(mean = ~ mean(., na.rm = TRUE),
                          median = ~ median(., na.rm = TRUE),
                              sd = ~ sd(., na.rm = TRUE)),
                       .groups = "keep")

annual_percent <- (100*(annual_stats[2:5,3:ncol(annual_stats)] -           
                       annual_stats[rep(1,4),3:ncol(annual_stats)]) / 
                       annual_stats[rep(1,4),3:ncol(annual_stats)]) %>%
                      cbind(annual_stats[2:5,1:2],.)
  

# KEC - there is a bimodal distribution for the day-of-year for the maximum
# precipitation AND correspondingly runoff. 

# Group by year and select daily maximum discharge with corresponding date
max_annual_runoff <- centroid_all %>%
  mutate(Date = date,
         year = year(date)) %>%
  dplyr::select(c(Date,cf,year,runoff_in)) %>%
  addWaterYear() %>%
  dplyr::group_by(cf,waterYear) %>% 
  dplyr::slice_max(order_by = runoff_in, n=1, with_ties = FALSE) %>%
  mutate(doy = yday(Date),
         dowy = as.numeric(Date - as.Date(paste0(waterYear-1,"-10-01"))),
         season = case_when(month(Date) <= 5 ~ "spring",
                            month(Date) >= 8 ~ "fall",
                            month(Date) >5 & month(Date) <8 ~ "summer"))

# calculate slopes, or rate of annual change. Negative indicates earlier runoff
spring_runoff_yearly_change <- max_annual_runoff %>%
  filter(season == "spring") %>%
  group_by(cf) %>%
  dplyr::summarise(slope = coef(lm(doy ~ year))[2], .groups = "keep")

fall_runoff_yearly_change <- max_annual_runoff %>%
  filter(season == "fall") %>%
  group_by(cf) %>%
  dplyr::summarise(slope = coef(lm(doy ~ year))[2], .groups = "keep")

max_annual_precip <- centroid_all %>%
  mutate(Date = date,
         year = year(date)) %>%
  dplyr::select(c(Date,cf,year,precip_in)) %>%
  addWaterYear() %>%
  dplyr::group_by(cf,waterYear) %>% 
  dplyr::slice_max(order_by = precip_in, n=1, with_ties = FALSE) %>%
  mutate(doy = yday(Date),
         dowy = as.numeric(Date - as.Date(paste0(waterYear-1,"-10-01"))),
         season = case_when(month(Date) <= 5 ~ "spring",
                            month(Date) >= 8 ~ "fall",
                            month(Date) >5 & month(Date) <8 ~ "summer"))

# calculate slopes, or rate of annual change. Negative indicates earlier precip
spring_precip_yearly_change <- max_annual_precip %>%
  filter(season == "spring") %>%
  group_by(cf) %>%
  dplyr::summarise(slope = coef(lm(doy ~ year))[2], .groups = "keep")

fall_precip_yearly_change <- max_annual_precip %>%
  filter(season == "fall") %>%
  group_by(cf) %>%
  dplyr::summarise(slope = coef(lm(doy ~ year))[2], .groups = "keep")



ggplot(max_annual_runoff %>% filter(season == "spring"),
       aes(x = year(Date), y = doy, color = cf)) + 
  geom_point() +
  geom_smooth(method = lm) + 
  labs(x = "", y = "Day of maximum annual spring runoff")

ggplot(max_annual_precip,aes(x = doy, fill = cf)) + geom_histogram() + facet_wrap(~cf)

```


Save data

```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

save_variables <- c(park,spring_precip_yearly_change, fall_precip_yearly_change)

## path to data folder (from project directory)
out_path <- paste0("data/park/",park,"/",park,"_report_data.RData")

save(save_variables, 
     file= out_path)


```

## Examples

1. Example maps
```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}
# Optional view data

mapviewOptions(basemaps = c("Esri.WorldStreetMap", "Esri.WorldImagery","Esri.WorldShadedRelief"))

mapview(koppen_park,
        zcol = "K_vals",
        #aes(color = color),
        col.regions = koppen_park$color %>% unique(),
        #at = koppen_park$K_vals %>% unique(),
        alpha = 0,
        homebutton = FALSE,
        layer.name = "Koppen") +
  mapview(park_boundary, 
        col.regions = "#74a089", 
        alpha.regions = .5, 
        lwd = 2, 
        #popup = FALSE, 
        #legend = F, 
        homebutton = FALSE,
        layer.name = paste0(park," Park Boundary")) +
  mapview(park_watershed,
          col.regions= NA, 
          alpha.regions = 0, 
          lwd = .25, 
          popup = FALSE, 
          legend = FALSE, 
          homebutton = FALSE,
          label = FALSE) +
  mapview(park_flowlines,
          col.regions = "darkblue",
          lwd = 0.5,
          popup = FALSE, 
          legend = FALSE, 
          homebutton = FALSE,
          label = FALSE) +
  # UNCOMMENT IF AVAILABLE
  mapview(dplyr::summarize(watersupply_watershed),
          col.regions = "#E69F00", 
          alpha.regions = .5, 
          #popup = FALSE, 
          #legend = F, 
          homebutton = FALSE,
          layer.name = "Water Supply Watershed",
          legend = FALSE) +
  mapview(watersupply_flowlines,
          col.regions = "darkblue",
          lwd = 0.5,
          popup = FALSE, 
          legend = FALSE, 
          homebutton = FALSE,
          label = FALSE) +
    mapview(nwis_groundwater,
            cex = 6,
            col.regions = c("#8C86A0"),
            label = FALSE,
            homebutton = FALSE,
            layer.name = "NWIS Wells") +
  mapview(nldi_watershed,
          col.regions= NA, 
          alpha.regions = 0, 
          lwd = .5,
          color = "#C0532B",
          popup = FALSE, 
          legend = FALSE, 
          homebutton = FALSE,
          label = FALSE) +
  mapview(POD_supply,
          col.regions = c("#E69F00"), # orange
          alpha.regions = 1,
          alpha = 1,
          cex = 6, 
          layer.name = "Park Water Supply & Watershed",
          homebutton = FALSE,
          label = FALSE) +
  mapview(nwis_stream,
            cex = 6,
            col.regions = c("#C0532B"),
            homebutton = FALSE,
            layer.name = "NWIS Stream Gages & watersheds")


  #mapview(koppen_cent,
  #        layer.name = "Centroids")

color_list = c("#882314", "#C0532B", "#CF932C", "#674D53", "#8C86A0", "#724438",
               "#D5AB85","#01353D", "#088096", "#58B3C7", "#7AD4E4", "#B8FCFC",
               "#293633", "#3D5051", "#6B7F7F", "#87A1C7", "#516B95", "#304F7D",
               "#0067A2", "#DFCB91", "#CB7223", "#289A84", "#7FA4C2", "#AF7E56")

```


2. Example Tables
```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}

# kable tips:
# https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html

df <- annual_stats %>%
        dplyr::select(
          cf = cf, 
          AET = aet_in_mean,
          Runoff = runoff_in_mean,
          "Runoff Variability" = runoff_in_sd,
          "Days > Hist 95th <br> Percentile Runoff" = days_gt_95roff_mean,
          "Days Precip" = days_w_pcp_mean,
          "Days SWE" = days_w_swe_mean) %>%
        mutate_if(is.numeric, round, digits = 3) %>%
        t() %>% 
        as.data.frame() %>%
        janitor::row_to_names(row_number = 1) %>% 
        dplyr::select(c("Historical","Hot Dry", "Hot Wet", "Warm Dry", "Warm Wet"))



kable(df, digits = 2, escape = FALSE, booktabs = T) %>%
  kable_styling() %>%
kableExtra::landscape() %>%
  #kable_styling(full_width = F) %>%
    kable_paper(full_width = F)
```

3. Example Timeseries
```{r, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}
ggplot(centroid_seasonal %>% filter(y < 2010 | y > 2050),
       aes(x = y, y = accumswe_in, color = as.factor(cf))) + 
#  geom_violin() + 
#  geom_boxplot(width = 1) +
  geom_line() +
   labs(x = "year", y = "Days per year > 92F") + 
  scale_color_manual("",values = c("gray40","darkred","cornflowerblue","pink","navy"))# +
  #facet_wrap(~season, scales = "free")
```
