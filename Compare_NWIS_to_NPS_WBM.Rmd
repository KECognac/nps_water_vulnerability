---
title: "Compare_NWIS_to_NPS_WBM"
author: "KEC"
date: "2024-07-02"
output: html_document
editor_options: 
  chunk_output_type: inline
---

# Compare USGS Gage to NPS WBM

This markdown document compares NWIS gage flows to NPS WBM runoff

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

source('setup.R')

```


First select some gages

```{r, fig.width = 7}

# EITHER -- USE ALL PREVIOUSLY DOWNLOADED SITES (can filter later)

# List of previously downloaded site_nos
all_nwis_sites <- paste0("data/all/WBM_daily/wbm_daily_rasters/") %>%
  list.files(., full.names = TRUE) %>%
  as.data.frame() %>%
  mutate(site_no = gsub("^.*?WBM_daily_","",.) %>%
           gsub("_runoff_historic_gridmet_1980_2023.tif","",.))

gages <- get_gagesII(id = all_nwis_sites$site_no)



# OR -- Select n random reference gage sites from a state

#n <- 3
#state <- "UT"

# Get all NWIS sites -- here I choose all gages in Colorado with daily values
#all_nwis_sites <- whatNWISdata(stateCd = state, service = "dv") %>%
#  dplyr::filter(count_nu > 10000,
#                year(end_date) > 1990)

# Get NWIS Stream Gages that are "reference gages"
#gages <- get_gagesII(id = all_nwis_sites$site_no) %>%
#  dplyr::filter(class == "Ref") %>%
#  sample_n(.,n)

# Now select NWIS sites that are in the reference gages 
#gages <- gages %>%
#  left_join(., all_nwis_sites, by = c("staid" = "site_no")) %>%
#  distinct(staid, .keep_all = TRUE)


# Download data from reference stream sites
nwis_stream_discharge <- 
  dataRetrieval::readNWISdv(siteNumbers = gages$staid,
                            parameterCd = c('00060','00065')) %>%
  rename(., c("X_00060_00003" = "discharge", "X_00060_00003_cd" = "code")) %>%
  dplyr::filter(year(Date) >= 1980) %>%
  mutate(year = year(Date),
         discharge_cfd = discharge * 86400) 


ggplot(nwis_stream_discharge, 
       aes(x = Date, y = discharge_cfd, color = site_no)) + 
  geom_line() +
  theme_bw() +
  labs(x = "", y = "Daily Discharge (acre-feet)") +
  theme(legend.position="none") +
  scale_color_manual("", values = get_palette(c("#00AFBB", "#E7B800", "#FC4E07"), 10)) +
  facet_wrap(~site_no, scales = "free")

```


Now, use functions to get watersheds associated with stream gages

```{r}

nldi_watershed <- 
  gages$staid %>%
  purrr::map_dfr(~nldi_finder(site_no = .)) %>%
  dplyr::mutate(data = map(site_no, ~nldi_meta(site_no = .))) %>%
  unnest(cols = c(data)) %>%
  dplyr::left_join(st_drop_geometry(all_nwis_sites), by = "site_no")

#nldi_flowlines <- 
#  dplyr::summarize(nldi_watershed) %>%
#  mapNHDPlusHR() %>% 
#  dplyr::summarize()

mapviewOptions(fgb = FALSE, georaster = FALSE)
mapview(nldi_watershed,
        col.regions= "#C0532B", 
        alpha.regions = .4, 
        lwd = .5,
        color = "#C0532B",
        popup = FALSE, 
        homebutton = FALSE,
        layer.name = "NWIS Gage Watershed") +
  mapview(gages,
          cex = 3,
          col.regions = c("#C0532B"),
          homebutton = FALSE,
          layer.name = "NWIS Gage") #+
#  mapview(nldi_flowlines, 
#          color = "dodgerblue",
#          layer.name = "Streams")
```


# Define some functions 
```{r function}

get_wbm_aoi_historic <- function(park, 
                                 aoi, 
                                 aoi_name, 
                                 historic_years = 1980:2023, 
                                 download = FALSE, 
                                 path = "data/park/",
                                 wbm_vars = NULL ) {

  # Test vars
# park <- "WBM_daily"
#aoi_name <-  site_no
#    download = TRUE
 #   path <- "data/all"
  #  wbm_vars <- "runoff"  

  
if (download == TRUE) {
   
    # check that path to save files to exists
  if (!dir.exists(paste0(getwd(), "/", path, "/", park))) {
    dir.create(file.path(paste0(
      getwd(), "/", path, "/", park
    )), showWarnings = FALSE)
  }
  if (!dir.exists(paste0(getwd(), "/", path, "/", park, "/wbm_daily_rasters/"))) {
    dir.create(file.path(paste0(
      getwd(), "/", path, "/", park, "/wbm_daily_rasters/"
    )), showWarnings = FALSE)
  }
  
  # define projection
  proj <- "+proj=lcc +lat_0=42.5 +lon_0=-100 +lat_1=25 +lat_2=60 +x_0=0 +y_0=0 +ellps=WGS84 +units=m +no_defs"
  
  # transform aoi to crs of WBM data
  aoi <- st_transform(aoi, crs = proj)
  
  if (is.null(wbm_vars)) {
    wbm_vars <- c("soil_water",
                  "runoff",
                  "rain",
                  "accumswe",
                  "PET",
                  "Deficit",
                  "AET")
  }

  for (i in length(wbm_vars)) {
      
    wb_var <- wbm_vars[i]
    map_dat <- tidyr::crossing(historic_years, wb_var)
    
    # download each raster file to temp directory
    historic_rasters <- 
      map(1:nrow(map_dat), 
          function(x) {
            call <- paste0("/vsicurl/",
          "http://www.yellowstone.solutions/thredds/fileServer/daily_or_monthly/v2_historical/gridmet_v_1_5_historical/V_1_5_",
          map_dat$historic_years[x],
          "_gridmet_historical_",
          map_dat$wb_var[x],
          ".nc4"
        )
    
        r <- terra::rast(call)
    
        # assign informative names to each raster
        names(r) <- 
          paste(wb_var, 
            as.Date(paste0(map_dat$historic_years[x], 
                            "-", 
                            sub(".*_", "", names(r))), 
                            format = "%Y-%j"), 
                            sep = "_")
        return(r)
        }
      )
  
  ## combine all to single stack
  final_historic_stack <- terra::rast(historic_rasters)
  
  ## saved CRS and extent from raw downloaded file, that info does not attach to files pulled directly from URL
  crs(final_historic_stack) <- proj
  ext(final_historic_stack) <- c(-2060750, 2639250, -1915500, 1384500)
  
  # crop to aoi
  final_historic_stack <- terra::crop(final_historic_stack, aoi)
  
  # save final raster stack to file
  terra::writeRaster(
    final_historic_stack,
    filename = paste0(
      getwd(),
      "/",
      path,
      "/",
      park,
      "/wbm_daily_rasters/",
      park,
      "_",
      aoi_name,
      "_",
      wb_var,
      "_historic_gridmet_",
      historic_years[1],
      "_",
      historic_years[length(historic_years)],
      ".tif"
    ),
    overwrite = TRUE
    )
  }
 }
}


rast_read <- function(rast_list) {
    
    site_num <- as.character(parse_number(rast_list))
    
   rast(rast_list) %>% 
      as.data.frame(., xy = TRUE) %>%
      pivot_longer(-(x:y),
                   names_to = "var",
                   values_to = "val") %>%
      # Add historic to name
      mutate(site_no = site_num,
        var = 
               ifelse(
                 grepl('^accumswe|^runoff|^rain|^PET|^AET|^soil_water|^Deficit', var),
                 paste0("gridmet.historical_",var),var),
             val = val / (25.4*10) ) %>% # 10 = conversion factor, 25.4 = mm to in
      mutate(var = gsub("soil_water", "soilwater", var)) %>%
      # KEC - separate is VERY slow - can anyone suggest something quicker?
      separate(var, 
               into = c("gcm", "wbm_var", "date"), 
               sep = "_") %>%
      mutate(wbm_var = 
               str_replace_all(
                 wbm_var, 
                 c("runoff" = "runoff_in", 
                   "rain" = "rain_in", 
                   "AET" = "aet_in",
                   "PET" = "pet_in",
                   "accumswe" = "accumswe_in",
                   "soilwater" = "soil_water_in",
                   "Deficit" = "deficit_in")),
             date = as.Date(date)) 
  }


NSE_R2 <- function(observed,modeled) {
  dat <- data.frame(observed,modeled) %>%
    drop_na()
  NSE_R2 <- 1 - ( sum( (dat$modeled - dat$observed)^2 ) /
                  sum( (dat$observed - mean(dat$observed))^2 ) )
}

```


Now get WBM data for each gage -> start with just the first

```{r}


sites <- gages$staid

# DOWNLOAD WBM DATA --> This takes a while so comment out if already done

#for (i in 1:length(sites)) {
  
#  site_no <- sites[i]
#  aoi <- nldi_watershed[nldi_watershed$site_no == site_no,]

#  get_wbm_aoi_historic(
#    park = "WBM_daily",
#    aoi = aoi, 
#    aoi_name = site_no, 
#    download = TRUE,
#    path = "data/all",
#    wbm_vars = "runoff")

#  }                 


# Now import data --> note, rast_read aggregates using the daily mean of each
# grid cell in each watershed.

ws_wbm_fils <- paste0("data/all/WBM_daily/wbm_daily_rasters/") %>%
  list.files(., full.names = TRUE) %>%
  keep(., ~ str_detect(., str_c(sites, collapse = "|")))


# Also, this step takes a couple mins.
if (length(ws_wbm_fils) < 1) {
    
    stop("Must download wbm files first! Try get_wbm_aoi_historic arg download = TRUE.")
  
} else {
    
    ws_wbm <- ws_wbm_fils %>%
    purrr::map_dfr(~ rast_read(.)) %>%
      mutate(val = ifelse(wbm_var == "runoff_in" & val < 0, 0, val)) %>%
    dplyr::select(-c(x,y)) %>%
    group_by(date, wbm_var, gcm, site_no) %>%
    summarize_all(.funs = 
                    list(val = ~ mean(val, na.rm = TRUE)), 
                  .groups = "keep") %>%
    pivot_wider(names_from = "wbm_var", values_from = "val") 
  
    }


```



Now compare WBM to gage

```{r compare}

ws_wbm2 <- ws_wbm %>%
  dplyr::select(c(date,gcm,site_no,runoff_in)) %>%
  mutate(site_no =
           ifelse(nchar(site_no) < 8, paste0("0",site_no), site_no)) # above steps drop the first zero in the site_no. Add it back here. Should fix this above in future
  
# Fix col names in nwis_stream for join
nwis_stream_all <- 
  nwis_stream_discharge %>%
  rename(c("Date"="date")) %>%
  dplyr::filter(site_no %in% ws_wbm$site_no)

# convert runoff_in to discharge (multiply by watershed_area) and join with
# NWIS
ws_all <- 
  ws_wbm2 %>%
  rename(c("runoff_in" = "runoff_in_wbm")) %>%
  #mutate(site_no = paste0("0",site_no)) %>%
  left_join(., gages, by = join_by(site_no == staid)) %>%
    mutate(ws_area_sqft = drain_sqkm * 1.076e+7,
      discharge_cfd_wbm = (runoff_in_wbm / (12)) * ws_area_sqft,
           drain_sqft = drain_sqkm * 1.076e+7) %>%
  left_join(., nwis_stream_all, by = c("date","site_no")) %>%
  drop_na(discharge_cfd)

ws_all_annual <-
  ws_all %>%
  dplyr::group_by(site_no, year) %>%
  dplyr::mutate(discharge_cfd_wbm_cum = cumsum(discharge_cfd_wbm) - head(cumsum(discharge_cfd_wbm), 1L),
         discharge_cfd_cum = cumsum(discharge_cfd) - head(cumsum(discharge_cfd), 1L))


ggplot(ws_all %>% 
         dplyr::filter(year(date) < 1987)) + 
  geom_line(aes(x = date, y = discharge_cfd, color = "NWIS"), alpha = 1) +
  geom_line(aes(x = date, y = discharge_cfd_wbm, color = "WBM"), alpha = 0.7) + 
  theme_bw() +
  scale_color_manual("",values = c("dodgerblue","hotpink")) +
  labs(y = "Discharge (ft3/day)", x = "", title = "Daily Discharge") +
  facet_wrap(~site_no, scales = "free") + 
  theme(plot.title = element_text(hjust = 0.5))


```

```{r}

ggplot(ws_all_annual) + 
  geom_line(aes(x = date, y = discharge_cfd_cum, color = "NWIS"), alpha = 1) +
  geom_line(aes(x = date, y = discharge_cfd_wbm_cum, color = "WBM"), alpha = 0.6) + 
  theme_bw() +
  scale_color_manual("",values = c("dodgerblue","hotpink")) +
  labs(y = "Cumulative Discharge (ft3/day)", x = "", title = "Cumulative Annual Discharge") +
  facet_wrap(~site_no, scales = "free") + 
  theme(plot.title = element_text(hjust = 0.5))


```



