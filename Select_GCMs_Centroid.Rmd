---
title: "Retrieve and Process Climate Centroid Data"
author: "Caitlin Mothes and Katie Willi"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    theme: paper
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      warning = FALSE,
                      error = FALSE,
                      message = FALSE)
                      #cache = TRUE)

source("setup.R")
```

# Workflow to process MACA climate centroid data

**Codebase modified from <https://github.com/nationalparkservice/CCRP_automated_climate_futures>, led by Amber Runyon.**

Function to pull in all park centroid files:

```{r}
get_files <- function(park) {
  walk(list.files(
    paste0("data/park/", park, "/centroid/climate"),
    full.names = TRUE
  ),
  function(x) {
    tmp <- read_csv(x)
    # hacky way to pull filename to assign to env object
    name <-  str_sub(x, 33,-5)
    assign(name, tmp, envir = .GlobalEnv)
  })
  # also create a list of files
  files <- str_sub(list.files(
    paste0("data/park/", park, "/centroid/climate")), 1, -5)
}



```

Get data for park:

```{r}
park <- "BRCA"

## get all files
get_files("BRCA")

## create list of future and historic dfs
future_dfs <-
  str_sub(list.files(paste0("data/park/", park, "/centroid/climate")), 1, -5) %>%
  str_subset("future")

historic_dfs <-
  str_sub(list.files(paste0("data/park/", park, "/centroid/climate")), 1, -5) %>%
  str_subset("historic")
```

Set up some parameters?

```{r}
CFs_all <- c("Warm Wet", "Hot Wet", "Central", "Warm Dry", "Hot Dry")

##Color schemes

#Colors for CF values plotted side by side (match order of CFs vector)
colors5 <-  c("#6EB2D4", "#05689F", "#F6B294", "#CA0020","grey")
colors5.2 <- c("#6EB2D4", "#05689F", "grey", "#F6B294", "#CA0020")

# Switch for using Tercek csvs or downloading own data:
centroids_csv <- "Y" 
# Switch for method Indiv_method = c("corner", "pca"):
Indiv_method <- "pca" 
# Percentage of models to drop from ranking:
Percent_skill_cutoff = .1 
# Indicates whether Q/I present at bottom of plot to ID CF method used:
MethodCaption = "Y" 


# Threshold percentages for defining Climate futures. Default low/high:  0.25, 0.75
CFLow = 0.25     
CFHigh = 0.75

# Quantiles for temperature threshold calculations
QuantileLow = 0.05
QuantileHigh = 0.95

HotTemp = 95
ColdTemp = 32
PrecipThreshold = 0.05
```

Variable calculations:

```{r}
TFtoC <- function(T){(T-32)/1.8}

# VP from FAO -  https://www.fao.org/3/x0490e/x0490e07.htm
# could also use Buck 1981 for 'improved':
# Buck: VPDsat (mb) = (1.0007 + (3.46 * 10^-6 * P)) * 6.1121 * exp((17.50 * T)/(T+240.87))
# where T is deg C and P is atm pressure mb. Above for P > 800 (correction is minimal)
# Zackman re: Ragwala uses: Es = 611.6441 * 10^[(7.591386*T)/(240.7263+T)] where Tavg.
# Shelley sent Vaisala- to use Tavg for 611.6441 parameter - for 020 to +50 C.
# VPsatT = saturation VP @ T deg C [kPa]
# VPD [kPa]
VPsatT <- function(T){0.6108 * exp((17.27 * T)/(T + 237.3))}   

VPD <- function(TminF, TmaxF, RHmin, RHmax){
  Tmin <- TFtoC(TminF); Tmax <- TFtoC(TmaxF)
  es <- (VPsatT(Tmin)+VPsatT(Tmax))/2
  ea <- (VPsatT(Tmin)*RHmax*.01 + VPsatT(Tmax)*RHmin*.01)/2
  es - ea   }  # end VPD  
```

Clean data/create new vars

```{r}
# future data
Future_all <- future_all %>%
  mutate(Date=date,
         GCM=paste(GCM,RCP,sep="."),
         PrcpIn = pr/25.4,
         TmaxF = ((tasmax-273.15)*9/5) + 32,
         TminF = ((tasmin-273.15)*9/5) + 32,
         RHmaxPct = rhsmax,
         RHminPct = rhsmin,
         TavgF = (TmaxF+TminF)/2,
         Year = format(date,"%Y")) |> 
  dplyr::select(c("Date","GCM","PrcpIn","TmaxF","TminF","RHmaxPct","RHminPct","TavgF","Year", "RCP")) |> 
  mutate(VPD = VPD(TminF, TmaxF, RHminPct, RHmaxPct),
         DOY = yday(Date))


# historic data
Gridmet <- historical_all %>%
  mutate(Date = date,
         GCM = "gridmet.historical",
         PrcpIn = pr/25.4,
         TmaxF = ((tmmx-273.15)*9/5) + 32,
         TminF = ((tmmn-273.15)*9/5) + 32,
         RHmaxPct = rmax,
         RHminPct = rmin,
         TavgF = (TmaxF+TminF)/2,
         Year = format(date,"%Y")) %>% 
  dplyr::select(c("Date","GCM","PrcpIn","TmaxF","TminF","RHmaxPct","RHminPct","TavgF","Year")) |> 
  mutate(VPD = VPD(TminF, TmaxF, RHminPct, RHmaxPct),
         DOY = yday(Date))
```

PCA analysis for climate selection

<https://github.com/ccmothes/CCRP_automated_climate_futures/blob/master/scripts/custom-gcms/Plot_Table_Creation-custom-CFs.R> line 128 : custom_GCMs selection

<https://github.com/ccmothes/CCRP_automated_climate_futures/blob/master/scripts/Plot_Table_Creation.R>

Remove low skill models

```{r}

# Gridmet$Date = strptime(Gridmet$Date, "%Y-%m-%d")
# Future_all$Date = strptime(Future_all$Date, "%Y-%m-%d")

# # Subset Future_all to only be near future (2025-2055) and Baseline_all to only but until 2000
Baseline_all<-Gridmet
Baseline_all<-subset(Baseline_all,Year<2013)

ALL_FUTURE<-Future_all  
Future_all = subset(Future_all, Year >= Yr - (Range/2) & Year <= (Yr + (Range/2)))

#### Determine low-skill models
low_skill_models = read.delim('data/general/GCM_skill_by_region.txt',header=TRUE) %>%  #list from Rupp et al. 2016
  filter(
    if (region %in% Region) {
      Region == region
    } else {
      Region == "mean"
    }
  ) %>% top_n(n=length(unique(Future_all$GCM))/2*Percent_skill_cutoff, wt=Rank) #Cuts off percentage of models identified in Rmd

```

Set up for PCA

```{r}

####Set Average values for all four weather variables, using all baseline years and all climate models
BaseMeanPr = mean(Baseline_all$PrcpIn)
BaseMeanTmx = mean(Baseline_all$TmaxF)
BaseMeanTmn = mean(Baseline_all$TminF)

####Create Future/Baseline means data tables, with averages for all four weather variables, organized by GCM
Future_Means = aggregate(cbind(PrcpIn, TmaxF, TminF, TavgF)
                                    ~ GCM, Future_all, mean,na.rm=FALSE)   # , Future_all$Wind
# names(Future_Means) = c("GCM", "PrcpIn", "TmaxF", "TminF", "TavgF")    # , "Wind"

Baseline_Means = aggregate(cbind(PrcpIn, TmaxF, TminF, TavgF)~GCM, 
                                      Baseline_all, mean)   
# names(Baseline_Means) = c("GCM", "PrcpIn", "TmaxF", "TminF", "TavgF") 

#### add delta columns in order to classify CFs
Future_Means$DeltaPr = Future_Means$PrcpIn - Baseline_Means$PrcpIn
Future_Means$DeltaTmx = Future_Means$TmaxF - Baseline_Means$TmaxF
Future_Means$DeltaTmn = Future_Means$TminF - Baseline_Means$TminF
Future_Means$DeltaTavg = Future_Means$TavgF - Baseline_Means$TavgF

#### Set limits for CF classification
Pr0 = as.numeric(quantile(Future_Means$DeltaPr, 0))
Pr25 = as.numeric(quantile(Future_Means$DeltaPr, CFLow))
PrAvg = as.numeric(mean(Future_Means$DeltaPr))
Pr75 = as.numeric(quantile(Future_Means$DeltaPr, CFHigh))
Pr100 = as.numeric(quantile(Future_Means$DeltaPr, 1))
Tavg0 = as.numeric(quantile(Future_Means$DeltaTavg, 0))
Tavg25 = as.numeric(quantile(Future_Means$DeltaTavg, CFLow)) 
Tavg = as.numeric(mean(Future_Means$DeltaTavg))
Tavg75 = as.numeric(quantile(Future_Means$DeltaTavg, CFHigh))
Tavg100 = as.numeric(quantile(Future_Means$DeltaTavg, 1))

#### Designate Climate Future
Future_Means$CF1 = as.numeric((Future_Means$DeltaTavg<Tavg & Future_Means$DeltaPr>Pr75) | Future_Means$DeltaTavg<Tavg25 & Future_Means$DeltaPr>PrAvg)
Future_Means$CF2 = as.numeric((Future_Means$DeltaTavg>Tavg & Future_Means$DeltaPr>Pr75) | Future_Means$DeltaTavg>Tavg75 & Future_Means$DeltaPr>PrAvg)
Future_Means$CF3 = as.numeric((Future_Means$DeltaTavg>Tavg25 & Future_Means$DeltaTavg<Tavg75) & (Future_Means$DeltaPr>Pr25 & Future_Means$DeltaPr<Pr75))
Future_Means$CF4 = as.numeric((Future_Means$DeltaTavg<Tavg & Future_Means$DeltaPr<Pr25) | Future_Means$DeltaTavg<Tavg25 & Future_Means$DeltaPr<PrAvg)
Future_Means$CF5 = as.numeric((Future_Means$DeltaTavg>Tavg & Future_Means$DeltaPr<Pr25) | Future_Means$DeltaTavg>Tavg75 & Future_Means$DeltaPr<PrAvg)


#Assign full name of climate future to new variable CF
Future_Means$CF[Future_Means$CF1==1]=CFs_all[1]
Future_Means$CF[Future_Means$CF2==1]=CFs_all[2]
Future_Means$CF[Future_Means$CF3==1]=CFs_all[3]
Future_Means$CF[Future_Means$CF4==1]=CFs_all[4]
Future_Means$CF[Future_Means$CF5==1]=CFs_all[5]

#     Remove extraneous Climate Future columns
Future_Means$CF1 = NULL
Future_Means$CF2 = NULL
Future_Means$CF3 = NULL
Future_Means$CF4 = NULL
Future_Means$CF5 = NULL

#     Add column with emissions scenario for each GCM run
Future_Means$emissions[grep("rcp85",Future_Means$GCM)] = "RCP 8.5"
Future_Means$emissions[grep("rcp45",Future_Means$GCM)] = "RCP 4.5"

#### Select Corner GCMs
lx = min(Future_Means$DeltaTavg)
ux = max(Future_Means$DeltaTavg)
ly = min(Future_Means$DeltaPr)
uy = max(Future_Means$DeltaPr)

  #convert to points
ww = c(lx,uy)
wd = c(lx,ly)
hw = c(ux,uy)
hd = c(ux,ly)

pts <- Future_Means %>% filter(str_detect(GCM, paste(low_skill_models$GCM,collapse = '|'), negate = TRUE))

  #calc Euclidian dist of each point from corners
# KW: "corners" being the extremes: ww, wd, hw, hd
pts$WW.distance <- sqrt((pts$DeltaTavg - ww[1])^2 + (pts$DeltaPr - ww[2])^2)
pts$WD.distance <- sqrt((pts$DeltaTavg - wd[1])^2 + (pts$DeltaPr - wd[2])^2)
pts$HW.distance <- sqrt((pts$DeltaTavg - hw[1])^2 + (pts$DeltaPr - hw[2])^2)
pts$HD.distance <- sqrt((pts$DeltaTavg - hd[1])^2 + (pts$DeltaPr - hd[2])^2)

pts %>% filter(CF == "Warm Wet") %>% slice(which.min(WW.distance)) %>% .$GCM -> ww
pts %>% filter(CF == "Warm Dry") %>% slice(which.min(WD.distance)) %>% .$GCM -> wd
pts %>% filter(CF == "Hot Wet") %>% slice(which.min(HW.distance)) %>% .$GCM -> hw
pts %>% filter(CF == "Hot Dry") %>% slice(which.min(HD.distance)) %>% .$GCM -> hd

Future_Means <- Future_Means %>% mutate(corners = ifelse(GCM == ww,"Warm Wet",
                                         ifelse(GCM == wd, "Warm Dry",
                                                ifelse(GCM == hw, "Hot Wet",
                                                       ifelse( GCM == hd, "Hot Dry",NA))))) # -> Future_Means

FM <- Future_Means %>% dplyr::select("GCM","DeltaPr","DeltaTavg") %>%  
  filter(str_detect(GCM, paste(low_skill_models$GCM,collapse = '|'), negate = TRUE)) %>% 
  remove_rownames %>% column_to_rownames(var="GCM") 
CF_GCM = data.frame(GCM = Future_Means$GCM, CF = Future_Means$CF)
```

Run PCA

```{r}
#Select PCA GCMs

pca <- prcomp(FM, center = TRUE,scale. = TRUE) 

ggsave(paste0(OutDir, "/", SiteName, "_PCA-loadings.png"), plot=autoplot(pca, data = FM, loadings = TRUE,label=TRUE),width = PlotWidth, height = PlotHeight) 

pca.df<-as.data.frame(pca$x) 
write_csv(pca.df, paste0(OutDir, "/PCA-loadings.csv"))

#Take the min/max of each of the PCs
PCs <-rbind(data.frame(GCM = c(rownames(pca.df)[which.min(pca.df$PC1)],rownames(pca.df)[which.max(pca.df$PC1)]),PC="PC1"),
            data.frame(GCM = c(rownames(pca.df)[which.min(pca.df$PC2)],rownames(pca.df)[which.max(pca.df$PC2)]),PC="PC2"))

#Assigns CFs to diagonals
diagonals <- rbind(data.frame(CF = CFs_all[c(1,5)],diagonals=factor("diagonal1")),data.frame(CF = CFs_all[c(4,2)],diagonals=factor("diagonal2")))

PCA <- CF_GCM %>% filter(GCM %in% PCs$GCM) %>% left_join(diagonals,by="CF") %>% right_join(PCs,by="GCM")

ID.redundant.gcm <- function(PCA){
  redundant.diag=count(PCA,diagonals)$diagonals[which(count(PCA,diagonals)$n==1)] #ID redundant diagonal
  PC.foul = PCA$PC[which(PCA$diagonals == redundant.diag)] #ID which PC has the redundant diagonal
  PCA$GCM[which(PCA$PC == PC.foul & PCA$GCM != PCA$GCM[which(PCA$diagonals == redundant.diag)])] #ID GCM that is in both the  redundant diagonal and the duplicative PC
}

Future_Means %>% mutate(pca = ifelse(GCM %in% PCs$GCM[which(PCs$PC=="PC1")], as.character(CF), #assign PCs to quadrants and select those gcms
                                     ifelse(GCM %in% PCs$GCM[which(PCs$PC=="PC2")], as.character(CF),NA))) -> Future_Means #Future_Means

if(length(
  setdiff(CFs_all[CFs_all != "Central"],Future_Means$pca)) > 0){ #if a quadrant is missing 
  Future_Means$pca[which(Future_Means$corners == setdiff(CFs_all[CFs_all != "Central"],Future_Means$pca))] = setdiff(CFs_all[CFs_all != "Central"],Future_Means$pca) #assign corners selection to that CF
  if(nrow(PCA[duplicated(PCA$GCM),]) > 0) { #If there is a redundant GCM
    Future_Means$pca = Future_Means$pca #Do nothing - otherwise end up with empty quadrant. This line could be removed and make the previous statment inverse but it makes it more confusing what's gonig on that way
  } else{
    Future_Means$pca[which(Future_Means$GCM == ID.redundant.gcm(PCA))] = NA #Removes the GCM that is in redundant diagonal
  }
}
# KW: Which climate models do we want to use... do we select by PCA or Corner method (i.e., whatever `Indiv_method` is 
# KW: at the top of katie_wbm.R)
Future_Means <- Future_Means %>% mutate(select = eval(parse(text=paste0("Future_Means$",Indiv_method))))
WB_GCMs <- Future_Means %>% drop_na(select) %>% dplyr::select(c(GCM,CF))

rm(lx,ux,ly,uy,ww,wd,hw,hd, pts, FM, pca,pca.df,PCs,diagonals,PCA) 

```
