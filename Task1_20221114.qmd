---
title: "NPS Update"
format:
  html:
    self-contained: true
    self-contained-math: true
editor: visual
execute:
  cache: false
  echo: false
  warning: false
  error: false 
---

```{r}
library(tidyverse)
library(sf)
library(mapview)
library(ggpubr)
library(kableExtra)
library(plotly)
library(lubridate)
```

This report aims to update NPS on our progress related to **Task 1 in our Statement of Work:**

*Compile available data and information describing the hydrology, climate, and water supplies of priority NPS-identified parks (e.g., DEVA, JOTR, and MOJA).*

-   *Examples: Hydrologic data may include stream and spring flow data, groundwater level data, and water quality data associated with specific sources of NPS water supplies or suitable analogs. This may also include information describing contributing basins (e.g., catchment areas, groundwater recharge areas, surface water/groundwater interaction, and output from water balance models). Climate data may include historical precipitation and temperature data and locations and monitored parameters of weather stations and SNOTEL sites. Water supply information may include types of supplies (i.e., surface water or groundwater), point-of-diversion locations, diversion amounts, NPS-observed supply challenges, etc.*

### Current Mining Approach

We have developed several self-contained (i.e., no local data inputs necessary) functions in R that pull relevant data sets for any selected park units in the contiguous US (CONUS). Organizing our workflow in this way will allow to quickly pull information .... BLAH!

Because the end-goal of this project is to assess the water supply and climatic challenges of many park units, our primary focus has been to mine data sets that are available across CONUS so that the bulk of our analyses can be consistent and comparable across our assessments. Nationally available field sampling/instrumentation datasets that we are utilizing include the National Water Quality Portal, the National Water Information System, and NPS Aquarius. Modelled/generalized dataset include gridded water balance models (Tercek et al., 2021), freshwater use projections (Warziniack et al., 2022), and groundwater recharge estimates (Wollock, 2003). Additional national-scale datasets include the National Land Cover Dataset's Land Use Change Index, infrastructure layers from the National Park Service (), and the National Inventory of Dams ().

Though our focus is centered around utilizing nationally-available datasets, we would lose key information by not exploring more localized sources of data, including state-run water monitoring programs and state water rights data. Therefore, we have also pulled relevant state-specific datasets associated with our test parks: Death Valley, Mojave Desert, and Joshua Tree National Parks.

Data can be collected using two separate areal extents: 1) data within some distance of the park boundaries, and 2) data contained within the parks' surface water contributing area. Park unit boundaries are downloaded from the NPS-IRMA DataStore; currently we have been selecting data that is within 33.3 kilometers of each park unit. For surface water contributing areas, we utilize the R package `nhdplusTools` to select NHDPlus Version 2 features and to delineate watersheds for all surface water features within each park unit.

![Maps showing the two different data pulling approaches used for pulling data. Here, we are downloading water right point-of-diversion data associated with Death Valley National Park's park boundary (right) and its surface water contributing area (left)..](data/1_report/DEVA_pull_example.png){fig-align="center"}

The following maps and tables represent some of the data that we have currently pulled for each test park. For a complete list datasets we have pulled data from, see the **Tables** attachment.

```{r}
try(plyr::ldply(list.files(path="src/",
                       pattern="*.R",
                       full.names=TRUE),
            source))

# import park units
park <- c("DEVA","MOJA","JOTR")
park_boundary <- getParkBoundary(park = park)

park_buffer <- park_boundary %>% 
    sf::st_buffer(., dist = 0.3) # dist in dd; approximately 33.3 kilometers

# delineate surface wawter contributing areas per park
# watershed <- getWatersheds(aoi = park_boundary, dist = 0, save = TRUE, path = 'data/1_report/watershed.RDS')

watershed <- readRDS('data/1_report/watershed.RDS') %>%
  # dissolve for data pulling:
  group_by(REGION) %>%
  summarize()

watershed_split <- readRDS('data/1_report/watershed.RDS')

# put al of these areas of interest together for a single data pull"

aoi_split <- sf::st_union(watershed, park_buffer)

aoi <- aoi_split %>%
  summarize()
```

## Water Rights Data

### **Where are there water rights?**

We pulled water rights point-of-diversion locations from the states of California and Nevada using the `getPODCalifornia()` and `getPODNevada()` functions.

```{r}
# Download water right PODs from Nevada database:
# nv_water_rights <- getPODNevada(aoi = aoi, save = T, path = 'data/1_report/nv_water_rights.RDS')
nv_water_rights <- readRDS('data/1_report/nv_water_rights.RDS') %>%
  st_join(select(aoi_split, UNIT_CODE), left = TRUE) %>%
  distinct(., .keep_all=TRUE)

# Download water right PODs from California database:
# ca_water_rights <- getPODNevada(aoi = aoi, save = T, path = 'data/1_report/ca_water_rights.RDS')
ca_water_rights <- readRDS('data/1_report/ca_water_rights.RDS') %>%
  st_join(select(aoi_split, UNIT_CODE), left = TRUE) %>%
  distinct(., .keep_all=TRUE)
```

```{r}
mapview(nv_water_rights, 
        col.regions = c("#56B4E9","#F0E442"), 
        zcol = 'PARK_RIGHT', 
        alpha.regions = 1, 
        alpha = 0.75, 
        cex = 4, 
        layer.name = "PODs") +
mapview(ca_water_rights,
        col.regions = c("#56B4E9","#F0E442"), 
        zcol = 'PARK_RIGHT', 
        alpha.regions = 1, 
        alpha = 0.75, 
        cex = 4,
        legend = FALSE) +
mapview(park_buffer,
        col.regions = "black",
        alpha.regions = 0, 
        lwd = 1, 
        popup = FALSE, 
        legend = FALSE, 
        homebutton = FALSE,
        label = FALSE) +
mapview(watershed_split, 
        col.regions="#56B4E9", 
        alpha.regions = 0.33, 
        lwd = 0, 
        popup = FALSE, 
        legend = FALSE, 
        homebutton = FALSE,
        label = FALSE) +
mapview(park_boundary, 
        col.regions = "#74a089", 
        alpha.regions = 0, 
        lwd = 2, 
        popup = FALSE, 
        legend = F, 
        homebutton = FALSE,
        label = FALSE)
```

```{r}
ca_water_rights %>%
  sf::st_drop_geometry() %>%
  arrange((UNIT_CODE)) %>%
  kableExtra::kable('html') %>%
  kableExtra::kable_styling(position = 'center') %>%
  kableExtra::scroll_box(width = '900px', height = '500px')
```

```{r}
nv_water_rights %>%
  sf::st_drop_geometry() %>%
  arrange((UNIT_CODE)) %>%
  kableExtra::kable('html') %>%
  kableExtra::kable_styling(position='center') %>%
  kableExtra::scroll_box(width = '900px', height = '500px')

rm(ca_water_rights,nv_water_rights)
```

### What documents exist related to park water rights?

We can list metadata for park water rights dockets in NPS-IRMA DataStore with `inventoryDataStore()`, and then download them with `getDataStore()` .

```{r}
dockets <- pullDataStore(park = park) %>%
  filter(referenceType == "Docket")

dockets %>%
  sf::st_drop_geometry() %>%
  kableExtra::kable('html') %>%
  kableExtra::kable_styling(position='center') %>%
  kableExtra::scroll_box(width = '900px', height = '500px')
rm(dockets)
```

# Water and Weather Datasets

### Where is there [USGS flow data](https://waterdata.usgs.gov/nwis)?

We are able to inventory NWIS locations, as well as the type of data being collected there, within an area of interest with `inventoryNWIS()`. We can then download the raw continuous data using `importNWIS()`.

```{r}
# pull metadata on USGS locations with flow data
# nwis_all <- pullNWIS(aoi = aoi, save = T, path = 'data/1_report/nwis_all.RDS')
nwis_all <- readRDS('data/all/nwis_all.RDS') %>%
  mutate(site_type = ifelse(is.na(site_type), "Other", site_type)) %>%
  filter(flow_data == "Flow") %>%
  st_join(select(aoi_split, UNIT_CODE), left = TRUE) %>%
  distinct(., .keep_all=TRUE) %>%
  select(UNIT_CODE, site_no, site_name, site_type, parameter_type, date_range, n_obs)
```

```{r}
mapview((nwis_all), col.regions = wesanderson::wes_palette("FantasticFox1", 4, type = "continuous"), 
        zcol = 'site_type',
        alpha.regions = 1,
        alpha = 0.75,
        cex = 5, 
        layer.name = "NWIS Flow Sites") +
mapview(park_buffer,
        col.regions = "black",
        alpha.regions = 0, 
        lwd = 1, 
        popup = FALSE, 
        legend = FALSE, 
        homebutton = FALSE,
        label = FALSE) +
mapview(watershed_split, 
        col.regions="#56B4E9", 
        alpha.regions = 0.33, 
        lwd = 0, 
        popup = FALSE, 
        legend = FALSE, 
        homebutton = FALSE,
        label = FALSE) +
mapview(park_boundary, 
        col.regions = "#74a089", 
        alpha.regions = 0, 
        lwd = 2, 
        popup = FALSE, 
        legend = F, 
        homebutton = FALSE,
        label = FALSE)
```

```{r}
nwis_all %>%
  sf::st_drop_geometry() %>%
  arrange((UNIT_CODE)) %>%
  kableExtra::kable('html') %>%
  kableExtra::kable_styling(position='center') %>%
  kableExtra::scroll_box(width='900px',height='500px')
rm(nwis_all)
```

### Where is there [NPS Aquarius data](https://irma.nps.gov/AQWebPortal/Data/Map)?

We can download continuous data from NPS-Aquarius for a park of interest using `importAquarius()`.

```{r}

# aquarius <- downloadAquarius(park = park, save = T, path = 'data/1_report/all_aquarius.RDS') 

aquarius <- readRDS('data/1_report/all_aquarius.RDS') %>%
  distinct(.keep_all=TRUE) %>%
  mutate(timestamp = lubridate::ymd_hms(timestamp),
         year = lubridate::year(timestamp)) %>%
  group_by(siteID, Location.Type, parameter, Long, Lat, EPSG) %>%
  summarize(n_obs = n(),
            range = ifelse(min(year) == max(year), 
                           paste0(min(year)),
                           paste0(min(year), "-", max(year)))) %>%
  mutate(flow_data = ifelse(grepl("velocity|WaterPressure|discharge|flow|height|level|stage|depthtowater", 
                                  parameter, ignore.case=T) &! grepl("sediment", parameter, ignore.case = T), "Flow", "Other")) %>%
  dplyr::filter(flow_data == "Flow") %>%
  select(siteID, Location.Type, parameter, n_obs, range, Lat, Long) %>%
  sf::st_as_sf(coords=c("Lat","Long"), crs=4326) %>%
  sf::st_transform(st_crs(aoi)) %>%
  st_join(select(aoi_split, UNIT_CODE), left = TRUE) %>%
  distinct(., .keep_all=TRUE)
```

```{r}
mapview(aquarius,
        zcol = 'Location.Type',
        col.regions = c("#E69F00", # light orange
                        "#56B4E9", # light blue
                        "#009E73", # green
                        "#F0E442"), # yellow
        layer.name = "Aquarius Sites") + 
mapview(park_buffer,
        col.regions = "black",
        alpha.regions = 0, 
        lwd = 1, 
        popup = FALSE, 
        legend = FALSE, 
        homebutton = FALSE,
        label = FALSE) +
mapview(watershed_split, 
        col.regions="#56B4E9", 
        alpha.regions = 0.33, 
        lwd = 0, 
        popup = FALSE, 
        legend = FALSE, 
        homebutton = FALSE,
        label = FALSE) +
mapview(park_boundary, 
        col.regions = "#74a089", 
        alpha.regions = 0, 
        lwd = 2, 
        popup = FALSE, 
        legend = F, 
        homebutton = FALSE,
        label = FALSE)
```

```{r}
aquarius %>%
  sf::st_drop_geometry() %>%
  arrange((UNIT_CODE)) %>%
  kableExtra::kable('html') %>%
  kableExtra::kable_styling(position='center') %>%
  kableExtra::scroll_box(width='900px',height='500px')
rm(aquarius)
```

### Where is there [Water Quality Portal data](https://www.waterqualitydata.us/)?

Download Water Quality Portal sites as well as the water quality data associated with them using `importWQPData()`.

```{r}
# # wqp_all <- downloadWQP(aoi = aoi, save = T, path ='data/1_report/wqp_data_all.RDS')
# wqp_all <- readRDS('data/1_report/wqp_all.RDS') %>%
#   distinct(.keep_all = TRUE) %>%
#   select(MonitoringLocationIdentifier,ActivityStartDate) %>%
#   mutate(year = year(as_date(ActivityStartDate))) %>%
#   group_by(MonitoringLocationIdentifier) %>%
#   summarize(n_obs = n(),
#             range = ifelse(min(year) == max(year), 
#                            paste0(min(year)), 
#                            paste0(min(year), "-", max(year)))) #%>%
#   #st_join(select(aoi_split, UNIT_CODE), left = TRUE)
```

```{r}
# mapview(wqp_all,
#         #zcol = 'Location.Type',
#         col.regions = "black",
#         layer.name = "WQP Sites") + 
# mapview(park_buffer,
#         col.regions = "black",
#         alpha.regions = 0, 
#         lwd = 1, 
#         popup = FALSE, 
#         legend = FALSE, 
#         homebutton = FALSE,
#         label = FALSE) +
# mapview(watershed_split, 
#         col.regions="#56B4E9", 
#         alpha.regions = 0.33, 
#         lwd = 0, 
#         popup = FALSE, 
#         legend = FALSE, 
#         homebutton = FALSE,
#         label = FALSE) +
# mapview(park_boundary, 
#         col.regions = "#74a089", 
#         alpha.regions = 0, 
#         lwd = 2, 
#         popup = FALSE, 
#         legend = F, 
#         homebutton = FALSE,
#         label = FALSE)
```

```{r}
# wqp_all  %>%
#   sf::st_drop_geometry() %>%
#   arrange((UNIT_CODE)) %>%
#   kableExtra::kable('html') %>%
#   kableExtra::kable_styling(position='center') %>%
#   kableExtra::scroll_box(width='900px',height='500px')
# rm(wqp_all)
```

### Where are there NOAA weather stations?

Download NOAA weather station data for a selected time period (here, from 1979-2022) using `importNOAA()`.

```{r}
# noaa_all <- getNOAA(aoi = aoi, startDate = "1979-10-01", endDate = "2022-09-30",
#                     save = T, path = "data/1_report/all_noaa.RDS")
noaa_all <- readRDS('data/1_report/all_noaa.RDS') %>%
  mutate(year = lubridate::year(lubridate::as_date(date))) %>%
  group_by(id) %>%
  summarize(range_1980 = ifelse(min(year) == max(year), 
                         paste0(min(year)), 
                         paste0(min(year), "-", max(year)))) %>%
  st_join(select(aoi_split, UNIT_CODE), left = TRUE)
   
```

```{r}
mapview(noaa_all,
        col.regions = "#CC79A7",
        cex = 3,
        layer.name = "NOAA Weather Stations") + 
mapview(park_buffer,
        col.regions = "black",
        alpha.regions = 0, 
        lwd = 1, 
        popup = FALSE, 
        legend = FALSE, 
        homebutton = FALSE,
        label = FALSE) +
mapview(watershed_split, 
        col.regions="#56B4E9", 
        alpha.regions = 0.33, 
        lwd = 0, 
        popup = FALSE, 
        legend = FALSE, 
        homebutton = FALSE,
        label = FALSE) +
mapview(park_boundary, 
        col.regions = "#74a089", 
        alpha.regions = 0, 
        lwd = 2, 
        popup = FALSE, 
        legend = F, 
        homebutton = FALSE,
        label = FALSE)
```

```{r}
noaa_all  %>%
  sf::st_drop_geometry() %>%
  arrange((UNIT_CODE)) %>%
  kableExtra::kable('html') %>%
  kableExtra::kable_styling(position='center') %>%
  kableExtra::scroll_box(width='900px',height='500px')
rm(noaa_all)
```

## Gridded/Interpolated Datasets

### [**Principal aquifers**](https://water.usgs.gov/GIS/metadata/usgswrd/XML/aquifers_us.xml) **in park units**

We have explored the option of pulling data associated with *Principal Aquifers of the 48 Conterminous United States, Hawaii, Puerto Rico, and the U.S. Virgin Islands* ([USGS, 2003](https://water.usgs.gov/GIS/metadata/usgswrd/XML/aquifers_us.xml#stdorder)); namely, selecting only aquifers that intersect park boundaries. Because many of these aquifers extend across large swaths of the US, we embedded an option to clip aquifer extents by a chosen distance outside of the park boundary (e.g., clipping associated aquifer extents to only 33.3 km around the park boundary).

```{r}
aquifers <- downloadAquifers(aoi = park_boundary, dist = 0.3)

mapview(aquifers, 
        zcol = "OBJECTID_1",
        col.regions = wesanderson::wes_palette("Zissou1", type = "continuous"),
        layer.name= "Aquifers within Park Units",
        popup = TRUE,
        legend = F) + 
mapview(park_boundary, 
        col.regions = "black", 
        alpha.regions = 0, 
        lwd = 2, 
        popup = FALSE, 
        legend = F, 
        homebutton = FALSE,
        label = FALSE)
rm(aquifers)
```

### [Mean Annual Ground-Water Recharge Index](https://water.usgs.gov/GIS/metadata/usgswrd/XML/rech48grd.xml)

Import the mean annual ground-water recharge index grid (Wollock, 2003) and clips to the area(s) of interest using `importGWRecharge()`.

```{r}
recharge <- downloadRecharge(aoi = aoi, dist = 0)

mapview(recharge[[1]], 
        col.regions = c("#F21A00","#E1AF00","#EBCC2A","#78B7C5","#3B9AB2"),
        layer.name= "Monthly Groundwater Recharge Index") + 
mapview(park_buffer,
        col.regions = "black",
        alpha.regions = 0, 
        lwd = 1, 
        popup = FALSE, 
        legend = FALSE, 
        homebutton = FALSE,
        label = FALSE) +
mapview(watershed_split, 
        col.regions="black", 
        alpha.regions = 0, 
        lwd = 1, 
        popup = FALSE, 
        legend = FALSE, 
        homebutton = FALSE,
        label = FALSE) +
mapview(park_boundary, 
        col.regions = "#74a089", 
        alpha.regions = 0, 
        lwd = 2, 
        popup = FALSE, 
        legend = F, 
        homebutton = FALSE,
        label = FALSE)
rm(recharge)
```

### Layers from the [NPS Gridded Water Balance Model](http://screenedcleanedsummaries.s3-website-us-west-2.amazonaws.com/) 

There are \~1,700 rasters associated with this database. Here we are showing just one, though all (or any combination thereof) of the summary rasters can be downloaded with the `importWBM()` function. However, the worklows linked to customizing outputs for the [*What water balance product do you need?*](https://screenedcleanedsummaries.s3.us-west-2.amazonaws.com/which_water_balance.html)dataset requires NPS VPN access.

```{r}
# importWBM(aoi = aoi, type = "PET")

pet_historical <- raster::raster('data/1_report/historical_pet_1980_1999.tif')

mapview(pet_historical, 
        col.regions = c("#F21A00","#E1AF00","#EBCC2A","#78B7C5","#3B9AB2"),
        layer.name= "PET (1980-1999)") + 
mapview(park_buffer,
        col.regions = "black",
        alpha.regions = 0, 
        lwd = 1, 
        popup = FALSE, 
        legend = FALSE, 
        homebutton = FALSE,
        label = FALSE) +
mapview(watershed_split, 
        col.regions="black", 
        alpha.regions = 0, 
        lwd = 1, 
        popup = FALSE, 
        legend = FALSE, 
        homebutton = FALSE,
        label = FALSE) +
mapview(park_boundary, 
        col.regions = "#74a089", 
        alpha.regions = 0, 
        lwd = 2, 
        popup = FALSE, 
        legend = F, 
        homebutton = FALSE,
        label = FALSE)
rm(pet_historical)
```

# Miscellaneous Datasets

### Trends in park visitation

Import park visitation data using `getVisitation()`.

```{r}
# download visitation data from NPS-Irma STATS
visitor_stats <- getVisitation(type = 'park', units = park, 
                               startYear = 1900, endYear = 2022) %>%
  group_by(UnitCode,Year) %>%
  summarize(Annual=sum(RecreationVisitors))
```

```{r}
plotly::ggplotly(ggplot() +
  geom_point(data = visitor_stats, aes(x = Year, y = Annual, color = UnitCode)) +
  geom_line(data = visitor_stats, aes(x = Year, y = Annual, color = UnitCode)) +
  scale_color_manual(values = c("#56B4E9",    # light blue
                                "#009E73",    # green
                                "#0072B2")) + # dark blue
  theme_bw() +
  labs(color="Park Unit") +
  ylab("Annual Visitors") +
  scale_y_continuous(labels = scales::comma))
rm(visitor_stats)
```
