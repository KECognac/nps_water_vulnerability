---
title: "Exploring Data at BRCA"
author: "Caitlin Mothes and Katie Willi"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: paper
    code_folding: show
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      error = FALSE,
                      message = FALSE)
source("setup.R")
#load("supp/all_objects.RData")
```

This workflow explores correlations between NPS's water balance model (NPS WBM), climate variables, stream flow, and groundwater levels in and around Bryce Canyon National Park (BRCA).

## Downloading data

##### Park watersheds

```{r, eval = TRUE, message = FALSE, warning = FALSE}
# get park boundary
park_boundary <- getParkBoundary(park = "BRCA")
# pull in the park watersheds as a starting AOI for pulling in WBM data:
park_watershed <- getWatersheds(aoi = park_boundary, save = FALSE)
# get NHD HR flowlines within the boundary
park_flowlines <- mapNHDPlusHR(aoi = summarize(park_watershed)) %>% 
  summarize()
```

##### Water supply watersheds

NPS water supply locations may not necessarily be within the park, and therefore their watersheds may not be represented in the park boundary's watersheds delineated above. So, here I am pulling in the water supply locations of interest, and delineating their own watersheds to ensure we capture them for pulling in more data. Water supply locations are found using the [Utah Division of Water Rights database](https://maps.waterrights.utah.gov/asp/wrplatGE.asp).

```{r, eval = TRUE, message = FALSE, warning = FALSE}
# get Utah points of diversion near BRCA
POD_Utah <- getPODUtah(aoi = park_watershed, dist = 0.1)
# filter to water supplies of interest
POD_park <- POD_Utah %>%
  dplyr::filter(WRNUM %in% c("61-893", "2061001M00")) %>% #, # current supply
  #"61-1143")) %>% # potential future supply
  distinct(LOCATION, .keep_all = TRUE) 
watersupply_watershed <- vector("list", nrow(POD_park))
# get the watersheds of different points:
for(i in 1:nrow(POD_park)){
  
  watersupply_watershed[[i]] <- POD_park[i,] %>% 
    getXYWatersheds(sf = ., coordinates = NULL)
  
}
watersupply_watershed <- watersupply_watershed %>%
  bind_rows() %>% 
  distinct(featureid, .keep_all = TRUE) #%>%
#... hard to tell from topo what the future supply's real watershed looks like...   # I'll need to look into this further at some point.
#filter(!featureid %in% c("10807991", "10807997"))
watersupply_flowlines <- mapNHDPlusHR(aoi = summarize(watersupply_watershed))
```

##### USGS stream gage watersheds

For many parks, the nearest USGS stream gage is far away. Therefore, we are pulling all NWIS gages within 100 km of the park boundary. Of those, we only select stream gages that are considered "reference" gages in the [GAGES-II database (Falcone, 2011)](https://pubs.usgs.gov/publication/70046617). Then, we delineate each of those gages' watersheds using the `get_nldi_basin()` function from the {nhdplusTools} package:

```{r, eval = TRUE, message = FALSE, warning = FALSE}
# area around the park ~ 100 km away:
aoi <- sf::st_buffer(park_boundary, dist = 0.3)
# locate NWIS daily flow locations in that radius:

# Streamflow data:
nwis <- listNWIS(aoi = aoi, dist = 0) %>%
  # daily values...
  filter(data_type_cd == "dv",
         # ... of flow
         code == "00060") %>%
  # for comparison purposes, need data from 1980 onwards
  filter(year(end_date) >= 1980)

# find the NWIS gages that are (crudely, probably) representative of natural conditions:
ref_gages <- get_gagesII(id = nwis$site_no) %>%
  filter(class == "Ref")
nwis <- nwis %>%
  filter(site_no %in% ref_gages$staid) %>%
  left_join(st_drop_geometry(ref_gages), by = c("site_no" ="staid"))
# for(i in 1:nrow(nwis)){
#   nwis$comid[i] <- discover_nhdplus_id(nwis[i,])
# }
# pull those sites' flow data
getNWIS(inventory = nwis, park = "misc", path = "data/")
# where are they?
# mapview(nwis) + mapview(park_boundary)
nldi_finder <- function(site_no){
  # Now, get those gages' watersheds using get_nldi_basin in the {nhdplusTools}.
  # Input for NLDI requires "USGS-" before the gage number
  nldi_nwis <- list(featureSource = "nwissite",
                    featureID = paste0("USGS-", site_no))
  
  invisible(suppressMessages(gage_basin <- nhdplusTools::get_nldi_basin(nldi_feature = nldi_nwis) %>%
                               st_transform(., 4269) %>%
                               mutate(site_no = site_no)))
  
  return(gage_basin)
  
}
nldi_meta <- function(site_no){
  # Now, get those gages' watersheds using get_nldi_basin in the {nhdplusTools}.
  # Input for NLDI requires "USGS-" before the gage number
  nldi_nwis <- list(featureSource = "nwissite",
                    featureID = paste0("USGS-", site_no))
  
  gage_basin <- nhdplusTools::get_nldi_characteristics(nldi_feature = nldi_nwis, type = "total")[[1]] %>%
    filter(characteristic_id %in% c("TOT_ELEV_MEAN", "TOT_ELEV_MAX", "TOT_ELEV_MIN")) %>%
    pivot_wider(-percent_nodata, values_from = characteristic_value, names_from = characteristic_id)
  
  return(gage_basin)
  
}
nldi_watershed <- nwis$site_no %>%
  map_dfr(~nldi_finder(site_no = .)) %>%
  mutate(data = map(site_no, ~nldi_meta(site_no = .))) %>%
  unnest() %>%
  left_join(st_drop_geometry(nwis), by = "site_no")
nldi_flowlines <- mapNHDPlusHR(aoi = summarize(nldi_watershed)) %>% 
  summarize()


#Get Gw sites!
nwis_groundwater <- listNWIS(aoi = aoi, dist = 0) %>%
  # locations with more than one days' worth of data:
  filter(begin_date != end_date,
         year(end_date) >= 2020,
         n_obs > 10,
         # groundwater sites only:
         site_type_cd == "GW",
         data_type_cd == "gw")
```

```{r, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}
mapview(park_boundary, 
        col.regions = "#74a089", 
        alpha.regions = 0, 
        lwd = 2, 
        popup = FALSE, 
        legend = F, 
        homebutton = FALSE,
        label = FALSE) + 
  mapview(park_watershed,
          col.regions="#56B4E9", 
          alpha.regions = 0.33, 
          lwd = 0, 
          popup = FALSE, 
          legend = FALSE, 
          homebutton = FALSE,
          label = FALSE) +
  mapview(watersupply_watershed,
          col.regions="#002fa7", 
          alpha.regions = 0.33, 
          lwd = 0, 
          popup = FALSE, 
          legend = FALSE, 
          homebutton = FALSE,
          label = FALSE) +
  mapview(park_flowlines,
          col.regions = "darkblue",
          lwd = 0.5,
          popup = FALSE, 
          legend = FALSE, 
          homebutton = FALSE,
          label = FALSE) +
  mapview(filter(watersupply_flowlines, !NHDPlusID %in% c(70000200004597,70000200033909)),
          col.regions = "darkblue",
          lwd = 0.5,
          popup = FALSE, 
          legend = FALSE, 
          homebutton = FALSE,
          label = FALSE) +
  mapview(nldi_flowlines,
          col.regions = "darkblue",
          lwd = 0.5,
          popup = FALSE, 
          legend = FALSE, 
          homebutton = FALSE,
          label = FALSE) +
  mapview(POD_park,
          col.regions = c("#E69F00"), # orange
          alpha.regions = 1,
          alpha = 1,
          cex = 6, 
          layer.name = "Park Water Supply") +
  mapview(nldi_watershed,
          col.regions="#002fa7", 
          alpha.regions = 0.33, 
          lwd = 0, 
          popup = FALSE, 
          legend = FALSE, 
          homebutton = FALSE,
          label = FALSE)  +
  mapview(nwis,        
          col.regions = c("maroon"), # orange
          alpha.regions = 1,
          alpha = 1,
          cex = 6, 
          layer.name = "USGS Stream Gage") +
  mapview(filter(nwis_groundwater, site_no %in% c("374845112031001", "372035112194801", "374205112091501")),
          col.regions = c("lightblue"), # orange
          alpha.regions = 1,
          alpha = 1,
          cex = 6, 
          layer.name = "USGS Well")
```

Lastly, we dissolve all of these watersheds into a single shapefile that we have the option of using for pulling in more data.

```{r, eval = TRUE, message = FALSE, warning = FALSE}
# our AOI blob!
final_aoi <- park_watershed %>%
  bind_rows(watersupply_watershed) %>%
  bind_rows(nldi_watershed) %>%
  summarize()
```

### Pulling in explanatory variables to explain water supply levels

**KW REMINDER** Running list of things I'd like to explore:

-   GridMet (temp, precip, P-PET?, accumSWE, other wbm vars)... with a lag
-   DayMet (temp, precip, P-PET?, accumSWE, other wbm vars)... with a lag
-   StreamCat/landscape variables
-   Visitation's relationship to water use and level
-   Nearby weather station data
-   Nearby stream and GW data

Here I pull in NPS's gridded monthly water balance predictions (1km resolution!!!!). This data comes from [Which Water Balance Model Do You Need? -\> Historical THREDDS](https://screenedcleanedsummaries.s3.us-west-2.amazonaws.com/which_water_balance.html). The function below downloads and crops these gridded monthly water balance predictions (from 1980-2023) for our area of interest. This includes the WBM variables soil water content, runoff, rain, accumulated snow water equivalent, PET, deficit, and AET. It then converts the information into a table. The coordinates of the grid centroids are preserved. For all variables across all years, this takes a little over an hour (for daily GridMET). 

```{r, eval = FALSE}
# Grab gridmet-derived WBM variables across BRCA water supply well contributing area:
# big downloads coming up... make sure they don't break:
options(timeout = 9000)

wbm_gridmet_vars <- getHistoricWBMGridMET(time = "monthly",
                                          park = "misc",
                                          aoi = st_transform(summarize(watersupply_watershed), 4326),
                                          path = "data/",
                                          wb_vars = c("soil_water", "runoff", "rain",
                                                      "accumswe", "PET", "Deficit", "AET"))
```

Here, I am also downloading additional gridded climate characteristics from GridMET using `climateR::getGridMET`. This includes temperature, precipitation, relative humidity, PET, wind speed, and vapor pressure deficit. This data is at 4km resolution.

```{r, eval = FALSE}
# watersupply <- st_transform(summarize(watersupply_watershed), 4326)

# Get all gridMET across BRCA water supply well contributing area:
# gridmet_vars <- get_gridMET(path = "data/", 
#                             park = "misc", 
#                             aoi = watersupply, 
#                             vars = c("tmmx", "tmmn", "pr", "rmax", "rmin", "pet", "etr", "vpd", "vs"), 
#                             start = "1979-01-01", 
#                             end = "2023-12-31")
```

Next, I download DayMET using `daymetr::daymet_data()`. This includes swe, srad, dayl, vp, tmin, tmax, and prcp. This data is at 1km resolution.

```{r, eval = FALSE}
# Get daymet across BRCA water supply well contributing area:
# get_dayMET <- get_dayMET( path = "data/", 
#                           park = "misc",
#                           # this data takes forever to download, so I'm only doing it for the water supply watershed
#                           aoi = st_transform(summarize(watersupply_watershed), 4326),
#                           vars = c("swe", "srad", "dayl", "vp", "tmin", "tmax", "prcp"))
```

Load in the gridded datasets downloaded above:

```{r}
wbm_gridmet_vars <- list.files("data/misc/wbm_gridmet_hist_monthly/temp/", full.names = TRUE) %>%
    map_dfr(~read_csv(.)) 
gridmet_vars <- list.files(paste0("data/misc/gridmet_hist_monthly/"), full.names = TRUE) %>%
    map_dfr(~data.table::fread(.)) %>%
    mutate(val = case_when(var %in% c("vpd", "vs", "tmmx", "rmax", "tmmn", "rmin") ~ mean,
                           # is this the right approach?
                           var %in% c("pet", "etr", "pr") ~ sum)) %>%
    select(x, y, ym, var, val) 
```




```{r, eval = TRUE}
# function to grab gridded vars at either a single point, or across
# an area of interest (should make real function and add to src):
raster_puller <- function(data, point = NULL, aoi = NULL){
  
  # if trying to get just a point...
  if(is.null(aoi)){
    
    point <- point %>%
      select(geometry) %>%
      st_transform(4326)
    
    tab_data <- data %>% 
      distinct() %>%
      st_as_sf(coords = c("x", "y"), crs = st_crs(4326)) %>%
      as_tibble()
    
    # create unique identifier for every coordinate:
    ID_raster <- data %>%
      select(x, y) %>%
      distinct() %>%
      st_as_sf(coords = c("x", "y"), crs = 4326) %>%
      rowid_to_column()
    
    final <- point %>%
      # grab nearest raster centroid to point of interest's ID:
      mutate(rowid = sf::st_nearest_feature(., ID_raster)) %>%
      # Using that id, grab the actual coordinates of that raster cell:
      inner_join(., as_tibble(ID_raster) , by = "rowid") %>%
      # ... to use as a join for all the raster data:
      inner_join(tab_data, by = c("geometry.y" = "geometry")) %>%
      # drop the geometry of the point
      st_drop_geometry() %>%
      # remove the unnecessary raster ID:
      select(-rowid) %>%
      # preserve the coordinates of the raster grid (NOT the point of interest's coordinates)
      rename(geometry_grid = geometry.y)
    
  }
  
  # if trying to get an AOI ...
  # THIS DOESN'T REALLY WORK APPROPRIATELY, AS IT ONLY SELECTS GRIDS WHOSE CENTROIDS ARE WITHIN THE AOI
  if(is.null(point)){
    
    aoi <- aoi %>%
      st_transform(4326)
    
    # grab all data within the AOI
    final <- data %>%
      mutate(X = x, Y = y) %>%
      st_as_sf(coords = c("X", "Y"), crs = 4326) %>%
      .[aoi,] %>%
      st_drop_geometry()
  }
  
  return(final)
  
}

# gridMET data for the well's location:
gridmet_xy <- gridmet_vars %>%
  # use raster_puller to extract the monthly gridmet vars at our well:
  raster_puller(data = ., aoi = NULL, point = POD_park[1,]) %>%
  pivot_wider(names_from = "var", values_from = "val") 
# tack on xy for the end of all vars
colnames(gridmet_xy) <- paste0(colnames(gridmet_xy), ".gridmet.xy")

# gridMET data for the "watershed" of the well's aquifer:
# soil_water, runoff, rain, accumswe, PET, Deficit, AET
gridmet_ws <- gridmet_vars %>% 
  data.table::data.table() #%>%
#raster_puller(data = ., point = NULL, aoi = summarize(watersupply_watershed)) 

# Does it look right?
# mapview(st_as_sf(gridmet_ws, coords = c("x", "y"), crs = 4326)) + mapview(watersupply_watershed)

gridmet_ws <- gridmet_ws %>%
  pivot_wider(names_from = "var", values_from = "val") %>%
  group_by(ym) %>%
  select(-x, -y) %>%
  summarize_all(list(mean = mean, sum = sum), na.rm = TRUE)
# tack on .ws to the end of all vars
colnames(gridmet_ws) <- paste0(colnames(gridmet_ws), ".gridmet.ws")


# # dayMET data for the well's location:
# daymet_data <- daymet_vars %>%
#   # use raster_puller to extract the monthly gridmet vars at our well:
#   raster_puller(data = ., aoi = NULL, point = POD_park[1,]) %>%
#   pivot_wider(names_from = "var", values_from = "val") 
# # tack on xy for the end of all vars
# colnames(daymet_data) <- paste0(colnames(daymet_data), ".daymet.xy")
# 
# # dayMET data for the "watershed" of the well's aquifer:
# daymet_ws <- daymet_vars %>% 
#   data.table::data.table() #%>%
#   #raster_puller(data = ., point = NULL, aoi = summarize(watersupply_watershed)) 
# 
# # Does it look right?
# mapview(st_as_sf(daymet_ws, coords = c("x", "y"), crs = 4326)) + mapview(watersupply_watershed)
# 
# daymet_ws <- daymet_ws %>%
#   pivot_wider(names_from = "var", values_from = "val") %>%
#   group_by(ym) %>%
#   select(-x, -y) %>%
#   summarize_all(list(mean = mean, sum = sum), na.rm = TRUE)
# # tack on .ws to the end of all vars
# colnames(daymet_ws) <- paste0(colnames(daymet_ws), ".daymet.ws")

# Water Balance variables (based on GridMET) at the well location:
gridmet_wbm_xy <- wbm_gridmet_vars %>%
  raster_puller(data = ., point = POD_park[1,], aoi = NULL) %>%
  pivot_wider(names_from = "var", values_from = "val") 
colnames(gridmet_wbm_xy) <- paste0(colnames(gridmet_wbm_xy), ".wbm.xy")

# Water Balance variables (based on GridMET across the well contributing area:
gridmet_wbm_ws <-  wbm_gridmet_vars %>%
  data.table::data.table() #%>%
#raster_puller(data = ., point = NULL, aoi = summarize(watersupply_watershed)) 

# Does it look right?
#mapview(st_as_sf(gridmet_wbm_ws, coords = c("x", "y"), crs = 4326)) + mapview(watersupply_watershed)

gridmet_wbm_ws <- gridmet_wbm_ws %>%
  pivot_wider(names_from = "var", values_from = "val") %>%
  group_by(ym) %>%
  select(-x, -y) %>%
  summarize_all(list(mean = mean, sum = sum), na.rm = TRUE)
colnames(gridmet_wbm_ws) <- paste0(colnames(gridmet_wbm_ws), ".wbm.ws")
```

We can also locate the nearest NOAA weather stations with the most appropriate data record:

```{r, eval = TRUE}
# Find NOAA weather stations near our areas of interest
noaa_data <- getNOAA(aoi = st_buffer(final_aoi, 0.1), park = "misc") %>%
  data.table::data.table() %>%
  # WHAT THE VARS MEAN/UNITS:
  # prcp = Precipitation (tenths of mm)
  # snow = Snowfall (mm)
  # snwd = Snow depth (mm)
  # tmax = Maximum temperature (tenths of degrees C)
  # tmin = Minimum temperature (tenths of degrees C)
  # elevation = meters
  select(name, id, date, tmax, tmin, prcp, snow, snwd, elevation, geometry) %>%
  # Raw NOAA data is in "tenths of" units for temp and precip:
  mutate_at(c("tmax", "tmin", "prcp"), function(x) {x * 0.10})


noaa_data_sub <- noaa_data %>%
    # This is the nearest site to our loc. Have code to select this automatically
  # but haven't effectively incorporated it yet
  filter(name == "BRYCE CANYON NP HQRS") %>%
  st_drop_geometry() %>%
  mutate(ym = ym(substr(date, 1, 7))) %>%
  filter(year(ym) >= 2000 & year(ym) <= 2022) %>%
  select(-date, -geometry) %>%
  group_by(name, id, ym) %>%
  summarize_all(list(mean = mean, sum = sum), na.rm = TRUE)
colnames(noaa_data_sub) <- paste0(colnames(noaa_data_sub), ".noaa")


# tab_data <- noaa_data_sub %>%
#   as_tibble()
# ID_noaa <- noaa_data_sub %>%
#   group_by(name, id) %>%
#   summarize() %>%
#   rowid_to_column() 
# Find the nearest NOAA station to the wells:
# nearby_noaa <- ID_noaa %>%
#   filter(rowid == st_nearest_feature(POD_park, ID_noaa)[1]) %>%
#   st_drop_geometry() %>%
#   inner_join(., tab_data, by = "name") %>% 
#   dplyr::select(name, date, ym, tmax, tmin, prcp, snow, snwd)
```

Pulling in NWIS data:
```{r}
nwis_stream <- list.files("data/misc/nwis/dv/", full.names = TRUE) %>%
  map_dfr(~ read_csv(.) %>% 
            data.table::data.table() %>% 
            mutate(across(everything(), as.character))) %>%
  bind_rows() %>%
  mutate(dateTime = lubridate::ymd(dateTime),
         ym = ym(substr(dateTime, 1, 7)),
         flow_cfs = as.numeric(X_00060_00003)) %>%
  group_by(ym, site_no) %>%
  summarize(mean_cfs = mean(flow_cfs, na.rm = TRUE)) %>%
  left_join(st_drop_geometry(nldi_watershed), by = "site_no") %>%
  select(site_no, mean_cfs) %>%
  pivot_wider(names_from = "site_no", values_from = "mean_cfs") %>%
  rename(mammoth_ck = 3, usgs2 = 2)

# pull those sites' level data
nwis_gw <- dataRetrieval::readNWISgwl(nwis_groundwater$site_no) %>%
  # sites with long records (for now):
  filter(site_no %in% c("374845112031001", "372035112194801", "374205112091501")) %>%
  filter(sl_datum_cd == "NAVD88") %>%
  mutate(ym = ym(substr(lev_dt, 1, 7))) %>% 
  group_by(ym, site_no) %>%
  summarize(mean_sl_lev_va = mean(sl_lev_va, na.rm. = TRUE)) %>%
  select(ym, site_no, mean_sl_lev_va) %>%
  pivot_wider(names_from = site_no, values_from = mean_sl_lev_va) %>%
  #rename to non-numeric col name
  rename("swell" = "372035112194801",
         "nwell" = "374845112031001",
         "mwell" = "374205112091501")
```


## East Creek well data

BRCA has been measuring static water levels at their East Creek water supply wells since at least 2000. These wells are the current source for the park's public water supply. Well 1 is 90 feet deep with a suspected perforated casing from 50-60 feet below ground surface, and is the furthest well "upstream". Well 2 is 522 feet deep with a suspected 10-foot casing at the bottom of the well, and is about 400 feet directly down the valley from Well 1. Meanwhile, there is a third well that is likely similarly constructed to Well 2 and located next to Well 2. Well 3 has no pump and has likely never been in use.

A report written in 1998 about the well field described the system as being an alluvial aquifer recharged by infiltration of rainflow and streamflow into the East Creek drainage basin. Discharge of bedrock springs, such as Whiteman Spring, provide an additional source of recharge. The report also purported that the aquifer stores approximately 2.6 million cubic feet of water. A pump test performed in 1997 was also described, and culminated in the following results:

\- Hydraulic conductivity ratio - 1:10 (ratio of vertical to horizontal hydraulic conductivity)

\- Transmissivity (T) = 8900 ft\^2/day

\- Specific Yield (Sy) = 0.37

\- Kr = 150 feet/day

\- Aquifer thickness = 60 feet

\- Hydraulic gradient between well 1 and 2 = 0.0057 ft/ft

\- Hydraulic gradient upstream of well field = 0.0042 ft/ft

\- Average daily use = 112,000 gallons/day (or, 15,000 cubic feet/day) … during summer pumpage… so greatly overestimates winter use.


Here, we are pulling in the daily well level data for both wells:

```{r, eval = TRUE, message = FALSE, warning = FALSE}
well_data <- read_csv('data/park/BRCA/manual/BRCA_Well_Data.csv', na = c("NaN", "NA", "")) 

# includes some ~mystery~ wells.... so not using that data.
# well_data_other <- read_csv('data/park/BRCA/manual/BRCA_Well_Data_Digitized.csv', na = c("NaN", "NA", "")) 

names(well_data) <- make.names(names(well_data))

well_monthly <- well_data %>%
  dplyr::mutate(static_in = ifelse(Static..in. == "-", NA,
                                   ifelse(Static..in. == "NaN", NA, as.numeric(Static..in.))),
                date = mdy(Date),
                ym = ym(substr(date, 1, 7))) %>%
  dplyr::select(date,
                ym,
                well = Well,
                static_in) %>%
  group_by(well, ym) %>% 
  mutate(day_count = ifelse(is.na(static_in), 0, 1)) %>%
  summarize(level_observations = sum(day_count, na.rm = TRUE),
            level_mean = mean(static_in, na.rm = TRUE),
            level_median = median(static_in, na.rm = TRUE),
            level_sd = sd(static_in, na.rm = TRUE),
            level_spread = max(static_in, na.rm = TRUE) - min(static_in, na.rm = TRUE))

# The state of Utah also tracks monthly water use of that system:
water_supply <- getWaterSuppliersUtah(aoi = park_boundary) %>%
  filter(grepl("National Park", WRNAME, ignore.case=TRUE)) %>%
  .$WRID

# Well 1
water_use_1 <- getWaterUseUtah(WRID = water_supply)[[1]] %>%
  slice(1:39) %>%
  pivot_longer(-c("Year", "Method of Measurement"), names_to = "month", values_to = "use_acre_feet") %>%
  mutate(ym = ym(paste0(Year, "-", month))) %>%
  filter(month != "Annual inAcre Feet") %>%
  select(ym, use_acre_feet) %>%
  mutate(well = "Well 1")

# Well 2
water_use_2 <- getWaterUseUtah(WRID = water_supply)[[1]] %>%
  slice(51:nrow(.)) %>%
  dplyr::filter(!is.na(as.numeric(Year))) %>%
  pivot_longer(-c("Year", "Method of Measurement"), names_to = "month", values_to = "use_acre_feet") %>%
  mutate(ym = ym(paste0(Year, "-", month))) %>%
  filter(month != "Annual inAcre Feet") %>%
  select(ym, use_acre_feet) %>%
  mutate(well = "Well 2")

# join water use data
both_wells <- water_use_1 %>%
  bind_rows(water_use_2) %>%
  group_by(ym) %>%
  summarize(use_acre_feet = sum(as.numeric(use_acre_feet), na.rm = TRUE))

# Here we combine the average monthly static water levels with the monthly water use:
well_munge <- well_monthly %>%
  left_join(both_wells, by = c("ym"))

# NPS tracks monthly total park visitors. Here we pull that information in for the park:
visitors <- getUnitVisitation(units = "BRCA", startYear = 2000, endYear = 2023) %>%
  mutate(ym = ym(paste0(Year, "-", Month))) %>%
  select(ym, RecreationVisitors)
```

Done with getting all the data - time to munge it all together!
```{r, eval = FALSE}
# bind all the data together:
all_brca_data <- well_munge %>%
  left_join(visitors, by = ("ym")) %>%
  left_join(., mutate(gridmet_xy, ym.gridmet.xy = as_date(ym.gridmet.xy)), by = c("ym" = "ym.gridmet.xy")) %>%
  left_join(., mutate(gridmet_ws, ym.gridmet.ws = as_date(ym.gridmet.ws)), by = c("ym" = "ym.gridmet.ws")) %>%
  #left_join(., daymet_data, by = c("ym" = "ym.daymet.xy")) %>%
  #left_join(daymet_ws, by = c("ym" = "ym.daymet.ws")) %>%
  left_join(., mutate(gridmet_wbm_xy, ym.wbm.xy = as_date(ym.wbm.xy)), by = c("ym" = "ym.wbm.xy")) %>%
  left_join(., mutate(gridmet_wbm_ws, ym.wbm.ws = as_date(ym.wbm.ws)), by = c("ym" = "ym.wbm.ws")) %>%
  left_join(noaa_data_sub, by = c("ym" = "ym.noaa")) %>%
  left_join(nwis_stream, by = "ym") %>%
  left_join(nwis_gw, by = "ym") %>%
  mutate(season = case_when(month(ym) %in% c(12,1,2) ~ "Winter",
                            month(ym) %in% c(3,4,5) ~ "Spring",
                            month(ym) %in% c(6,7,8) ~ "Summer",
                            month(ym) %in% c(9,10,11) ~ "Fall"))

# THEN SAVE!
write_csv(all_brca_data, 'data/misc/all_vars_at_BRCA_wells.csv')
```

```{r}
all_brca_data <- read_csv('data/misc/all_vars_at_BRCA_wells.csv')
```


# ANALYZING

## Cross-correlation

Interpretation: a positive lag indicates that the well levels shift in response to the other variable. One lag unit = one day. A negative correlation indicates GW flows decrease with increasing variable magnitude. Positive correlation indicates GW levels decrease with increasing variable magnitude. Some of these make sense... others do not... none are that significant on their own. 

```{r, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}
site <- unique(all_brca_data$well)

sub_brca_data<- filter(all_brca_data, well == site[1]) %>%
  filter(lubridate::year(ym) >= "2004") %>%
  ungroup()

ccf_munger <- function(column){
  
  ts_vector <- sub_brca_data %>%
    select(column) %>%
    pull()
  #zoo::na.approx
  ts <- (ts(as.numeric(ts_vector), start = 1))
  
  well.depth <- (ts(sub_brca_data$level_mean, start = 1))
  
  result <- ccf(ts, well.depth, na.action = na.pass, type = "correlation", plot = FALSE, lag.max = 12)
  
  plot(result, main = paste0("Correlation of well data with ", column), xlab = "Lag", ylab = paste0("Correlation"))
  
  ccf_df <- tibble(lag_days = c(result$lag), 
                   correlation = c(result$acf)) %>%
    mutate(variable = column)
  
  return(ccf_df)
  
}

sub_names <- sub_brca_data %>%
  select(-c(well, ym, level_observations, level_spread, contains("geometry"), usgs2, id.noaa, name.noaa, season))


ccfs <- names(sub_names) %>%
  map(~ ccf_munger(column = .)) %>%
  bind_rows() 
ccf <- ccfs %>%
  group_by(variable) %>%
  # Vars impact well, never the other way around
  filter((lag_days) >= 0) %>%
  # what are the highest-correlated lags?
  filter(abs(correlation) == max(abs(correlation), na.rm = TRUE)) 
ccf %>%
  DT::datatable(filter = "none",
                caption = 'Results of cross-correlation of misc. variables with well level. Listed per variable is the highest-correlated lag time.',
                rownames = FALSE,
                fillContainer = T,
                escape = FALSE,
                options = list(dom = 't',
                               pageLength = nrow(.),
                               scrollY = '300px'))
```

Plots of the lagged vars agains well level:
```{r}
lag_explore <- all_brca_data %>%
  mutate(snwd_mean.noaa_lag6 = lag(snwd_mean.noaa, n = 6))

ggplot(lag_explore) +
  geom_point(aes(x = level_mean, y = snwd_mean.noaa_lag6)) +
  theme_bw()

ggplot(lag_explore) +
  geom_point(aes(x = level_mean, y = mwell)) +
  theme_bw()
```

Some plots of more variables through time:
```{r}
well_data <- ggplot(data = all_brca_data) +
  geom_line(aes(x = ym, y = level_mean, color = well)) +
  # geom_col(aes( x = ym, y = pr))
  #facet_wrap(~well, nrow = 2) +
  theme_bw() +
  xlab("") +
  ylab("Well Level (mm)") +
  scale_color_manual(values = c("#242546", "#DF2057")) +  # Set line colors
  theme(legend.position = "none")  # Move legend to the bottom
streamflow <- ggplot(data = filter(all_brca_data, well == "Well 1")) +
  geom_col(aes(x = ym, y = mammoth_ck), color = "#242546") +
  theme_bw() +
  xlab("") +
  ylab("Mammoth Ck. (mmd)")
precip <- ggplot(data = filter(all_brca_data, well == "Well 1")) +
  geom_col(aes(x = ym, y = pr.gridmet.xy), color = "#242546") +
  geom_point(aes(x = ym, y = pr.gridmet.xy), color = "#DF2057") +
  theme_bw() +
  xlab("") +
  ylab("Precip. (mm)")
precip_station <- ggplot(data = filter(all_brca_data, well == "Well 1")) +
  geom_col(aes(x = ym, y = prcp_sum.noaa), color = "#242546") +
  geom_line(aes(x = ym, y = prcp_sum.noaa), color = "#DF2057") +
  theme_bw() +
  xlab("") +
  ylab("NOAA pr. (mm)")
swe <- ggplot(data = filter(all_brca_data, well == "Well 1")) +
  geom_col(aes(x = ym, y = accumswe_sum.wbm.ws), color = "#242546") +
  theme_bw() +
  xlab("") +
  ylab("SWE (mm)")
use <- ggplot() +
  geom_col(data = all_brca_data, aes(x = ym, y = as.numeric(use_acre_feet))) +
  theme_bw() +
  xlab("") +
  ylab("Use (acre-ft)") +
  theme(legend.position = "none") 
visitation <- ggplot() +
  geom_col(data = filter(all_brca_data, !is.na(RecreationVisitors) & well == "Well 1"), 
           aes(x = ym, y = as.numeric(RecreationVisitors)),
           color = "#242546") +
  theme_bw() +
  xlab("Date") +
  ylab("Visitors")
ggarrange(well_data, use, streamflow, precip, precip_station, swe, visitation, ncol = 1, align = "v")
```


